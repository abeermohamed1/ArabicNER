{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testflair.ipynbT",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeermohamed1/ArabicNER/blob/master/Arabic%20NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKq9n6i70o81",
        "outputId": "a642c3ef-b7dc-432a-a1c6-044f5c7cbeca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install --upgrade flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/82/898d26ae4c7a8c2cb51dfc776c7b323b049981a08300d811e18ac12825a8/flair-0.6.0.post1-py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.3MB/s \n",
            "\u001b[?25hCollecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/db/712bee56f9ab20373508a5a1c662e1db49b407dacf03b5224c6171ed0a3d/pytest-6.0.1-py3-none-any.whl (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 11.3MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/4b/f29cb8cf226d49b14f0d18bd175916dd0054dc66e42488f2c808075ef5a8/konoha-4.6.1-py3-none-any.whl\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting transformers>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 39.3MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0+cu101)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.2MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/ed/b2b072c1d53388931e626ca0816cdb8e03416ad9a440c8d9e0e060859f41/Janome-0.4.0-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.3MB/s \n",
            "\u001b[?25hCollecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.1.0)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair) (1.15.0)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 61.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (1.14.48)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.17.48)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.15.2)\n",
            "Building wheels for collected packages: ftfy, mpld3, langdetect, sqlitedict, segtok, overrides, sacremoses\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=93718450337034a60d61022c546872cf0d4d6221e4a0a7c6236946c247dc276b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116677 sha256=7a405867e17762d340ec3dca63c6dcaf1fc068ab5162c2c7cc6066eb136d3f0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=6d49de234e3565e623c4d58b49b40c0cc46f868fa4e4b8a310bae623b2912861\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp36-none-any.whl size=14377 sha256=6717ddd43ab4dbca21e1925d9d061b2ad480a37d081a29f83765940620d6e7f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25021 sha256=30af7a225047e2373e09e8a3785507180e2bdb0cd2ba1e8dd05c90ebe9253ca6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=bed4219ba102a727da83a4c9246be5a8fe85ebd24b79af39c664455b742465bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=588201522fbd88906959e4d5f13d20de0b25a36e33775b00fddda4b15e467980\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built ftfy mpld3 langdetect sqlitedict segtok overrides sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, pytest, sentencepiece, bpemb, ftfy, overrides, konoha, mpld3, deprecated, tokenizers, sacremoses, transformers, langdetect, sqlitedict, segtok, janome, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.6.0.post1 ftfy-5.8 janome-0.4.0 konoha-4.6.1 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 pluggy-0.13.1 pytest-6.0.1 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.7.0 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "155j8tiVhMA_",
        "outputId": "d62f8a52-209d-4117-d282-05ce943458f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-cof_8_2s\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-cof_8_2s\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/4b/f29cb8cf226d49b14f0d18bd175916dd0054dc66e42488f2c808075ef5a8/konoha-4.6.1-py3-none-any.whl\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (4.41.1)\n",
            "Collecting transformers>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (0.22.2.post1)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 24.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (3.2.2)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (4.2.6)\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/db/712bee56f9ab20373508a5a1c662e1db49b407dacf03b5224c6171ed0a3d/pytest-6.0.1-py3-none-any.whl (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (2.8.1)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (1.6.0+cu101)\n",
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/ed/b2b072c1d53388931e626ca0816cdb8e03416ad9a440c8d9e0e060859f41/Janome-0.4.0-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 160kB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (3.6.0)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.6.0.post1) (0.1.2)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.6.0.post1) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair==0.6.0.post1) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair==0.6.0.post1) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair==0.6.0.post1) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair==0.6.0.post1) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair==0.6.0.post1) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.6.0.post1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.6.0.post1) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.6.0.post1) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.6.0.post1) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.6.0.post1) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair==0.6.0.post1) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.6.0.post1) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.6.0.post1) (1.7.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.6.0.post1) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.6.0.post1) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.6.0.post1) (8.4.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.6.0.post1) (20.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair==0.6.0.post1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.6.0.post1) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.6.0.post1) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.6.0.post1) (3.11.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.6.0.post1) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair==0.6.0.post1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair==0.6.0.post1) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair==0.6.0.post1) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair==0.6.0.post1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.0->flair==0.6.0.post1) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.6.0.post1) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.6.0.post1) (1.14.48)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.6.0.post1) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.6.0.post1) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.6.0.post1) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.6.0.post1) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.6.0.post1) (1.17.48)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.6.0.post1) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.6.0.post1-cp36-none-any.whl size=187752 sha256=00661003b4bd3c7ff3f8fa59c00b1d97ffb07f42284ac8863b57b53e51cfd71c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4vys069y/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: mpld3, ftfy, segtok, langdetect, sqlitedict, overrides, sacremoses\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116677 sha256=588d22bb51c92c9d77726a9ff98480ceee77596c17a720786015f7b9bfb1f40b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=c6b1dc8b68a42cc4fb6e9b5005bb8f4815c99fea4aac3f43bafaae030016f9d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25021 sha256=a12bac302d9ed3dec359908113a3225f6f0aae00853ae1abd2daabf3e55ebe54\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=e6ab2e889c3b07945b6b92790aba68d03870f0840889d67767741b865e6da562\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=1e422624c1e0c0c61f422024d8bce711bfca28ee73036cda6088ce39229ab0e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=04eb1622921ef6b8e1eb8797e748d672b3d587f53d59417420fca3618fead47b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=182155dc690013bd3c9307a50302179a3e72c47c258441f9da80bf58221300c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built mpld3 ftfy segtok langdetect sqlitedict overrides sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: overrides, konoha, deprecated, sentencepiece, bpemb, sacremoses, tokenizers, transformers, mpld3, ftfy, pluggy, pytest, segtok, janome, langdetect, sqlitedict, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.6.0.post1 ftfy-5.8 janome-0.4.0 konoha-4.6.1 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 pluggy-0.13.1 pytest-6.0.1 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcHhY2evDBnB",
        "outputId": "16671e8b-5b4b-4b0a-ad0a-7b17bbd232b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip uninstall  flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping flair as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jv8_Fb67HUc",
        "outputId": "7ea37b25-80f8-4e21-b2d0-2e6e4b43d5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip uninstall git+https://github.com/abeermohamed1/flair.git@abeermohamed1-patch-2-1#egg=flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Can't uninstall 'flair'. No files were found to uninstall.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyWtTGc_5xMA",
        "outputId": "4debf0e6-92b0-41f2-f33b-4d78dc35135a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install -e git+https://github.com/abeermohamed1/flair.git@abeermohamed1-patch-2-1#egg=flair\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining flair from git+https://github.com/abeermohamed1/flair.git@abeermohamed1-patch-2-1#egg=flair\n",
            "  Updating ./src/flair clone (to revision abeermohamed1-patch-2-1)\n",
            "  Running command git fetch -q --tags\n",
            "  Running command git reset --hard -q f3eae919b4106bbe05e6a5809f5a5027375634f6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from flair) (2.5.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.6.1)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.7)\n",
            "Requirement already satisfied: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (5.3.5)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.4.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.3)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.11.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->flair) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.1)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.5.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.8)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (1.14.15)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (45.2.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers>=2.3.0->flair) (0.15.2)\n",
            "Installing collected packages: flair\n",
            "  Found existing installation: flair 0.4.5\n",
            "    Can't uninstall 'flair'. No files were found to uninstall.\n",
            "  Running setup.py develop for flair\n",
            "Successfully installed flair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZIyPo84I4_w",
        "outputId": "15a7c616-de9a-459f-84dc-3136fedd213e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "\n",
        "pip install -e git+https://github.com/flair/GH-1593-pooled-embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8b48c9482173>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install -e git+https://github.com/flair/GH-1593-pooled-embeddings\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RON0KgYA75iB",
        "outputId": "895e568c-892b-4b5f-db23-906f6c87d735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "pip install --upgrade pytorch-pretrained-bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 36.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 39.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 42.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 45.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 51.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 53.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 53.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 53.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQx8aN6sKI8j",
        "outputId": "05619307-064d-43cf-a5e6-14b25c9b2b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pip install --upgrade bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 21.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEQswwI8-P4k",
        "outputId": "1a4498f8-1347-48a0-8898-7a7a392a49fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/src/flair'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/src/flair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IsgrLQJoeK0",
        "outputId": "ab1be27d-cebc-4e20-a19d-f73b0ffa0cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python 'setup.py' install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing flair.egg-info/PKG-INFO\n",
            "writing dependency_links to flair.egg-info/dependency_links.txt\n",
            "writing requirements to flair.egg-info/requires.txt\n",
            "writing top-level names to flair.egg-info/top_level.txt\n",
            "writing manifest file 'flair.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/file_utils.py -> build/bdist.linux-x86_64/egg/flair\n",
            "creating build/bdist.linux-x86_64/egg/flair/hyperparameter\n",
            "copying build/lib/flair/hyperparameter/parameter.py -> build/bdist.linux-x86_64/egg/flair/hyperparameter\n",
            "copying build/lib/flair/hyperparameter/__init__.py -> build/bdist.linux-x86_64/egg/flair/hyperparameter\n",
            "copying build/lib/flair/hyperparameter/param_selection.py -> build/bdist.linux-x86_64/egg/flair/hyperparameter\n",
            "creating build/bdist.linux-x86_64/egg/flair/models\n",
            "copying build/lib/flair/models/language_model.py -> build/bdist.linux-x86_64/egg/flair/models\n",
            "copying build/lib/flair/models/sequence_tagger_model.py -> build/bdist.linux-x86_64/egg/flair/models\n",
            "copying build/lib/flair/models/text_classification_model.py -> build/bdist.linux-x86_64/egg/flair/models\n",
            "copying build/lib/flair/models/text_regression_model.py -> build/bdist.linux-x86_64/egg/flair/models\n",
            "copying build/lib/flair/models/__init__.py -> build/bdist.linux-x86_64/egg/flair/models\n",
            "copying build/lib/flair/models/similarity_learning_model.py -> build/bdist.linux-x86_64/egg/flair/models\n",
            "creating build/bdist.linux-x86_64/egg/flair/visual\n",
            "copying build/lib/flair/visual/training_curves.py -> build/bdist.linux-x86_64/egg/flair/visual\n",
            "copying build/lib/flair/visual/__init__.py -> build/bdist.linux-x86_64/egg/flair/visual\n",
            "copying build/lib/flair/visual/activations.py -> build/bdist.linux-x86_64/egg/flair/visual\n",
            "copying build/lib/flair/visual/ner_html.py -> build/bdist.linux-x86_64/egg/flair/visual\n",
            "copying build/lib/flair/visual/manifold.py -> build/bdist.linux-x86_64/egg/flair/visual\n",
            "copying build/lib/flair/samplers.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/datasets.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/__init__.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/nn.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/optim.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/embeddings.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/inference_utils.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/data_fetcher.py -> build/bdist.linux-x86_64/egg/flair\n",
            "copying build/lib/flair/training_utils.py -> build/bdist.linux-x86_64/egg/flair\n",
            "creating build/bdist.linux-x86_64/egg/flair/trainers\n",
            "copying build/lib/flair/trainers/__init__.py -> build/bdist.linux-x86_64/egg/flair/trainers\n",
            "copying build/lib/flair/trainers/trainer.py -> build/bdist.linux-x86_64/egg/flair/trainers\n",
            "copying build/lib/flair/trainers/language_model_trainer.py -> build/bdist.linux-x86_64/egg/flair/trainers\n",
            "copying build/lib/flair/data.py -> build/bdist.linux-x86_64/egg/flair\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/file_utils.py to file_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/hyperparameter/parameter.py to parameter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/hyperparameter/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/hyperparameter/param_selection.py to param_selection.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/models/language_model.py to language_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/models/sequence_tagger_model.py to sequence_tagger_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/models/text_classification_model.py to text_classification_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/models/text_regression_model.py to text_regression_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/models/similarity_learning_model.py to similarity_learning_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/visual/training_curves.py to training_curves.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/visual/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/visual/activations.py to activations.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/visual/ner_html.py to ner_html.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/visual/manifold.py to manifold.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/samplers.py to samplers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/datasets.py to datasets.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/nn.py to nn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/optim.py to optim.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/embeddings.py to embeddings.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/inference_utils.py to inference_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/data_fetcher.py to data_fetcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/training_utils.py to training_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/trainers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/trainers/trainer.py to trainer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/trainers/language_model_trainer.py to language_model_trainer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flair/data.py to data.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flair.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flair.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flair.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flair.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flair.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/flair-0.4.5-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing flair-0.4.5-py3.6.egg\n",
            "Copying flair-0.4.5-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Removing flair 0.4.5 from easy-install.pth file\n",
            "Adding flair 0.4.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/flair-0.4.5-py3.6.egg\n",
            "Processing dependencies for flair==0.4.5\n",
            "Searching for langdetect==1.0.8\n",
            "Best match: langdetect 1.0.8\n",
            "Adding langdetect 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tabulate==0.8.6\n",
            "Best match: tabulate 0.8.6\n",
            "Adding tabulate 0.8.6 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for regex==2019.12.20\n",
            "Best match: regex 2019.12.20\n",
            "Adding regex 2019.12.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for bpemb==0.3.0\n",
            "Best match: bpemb 0.3.0\n",
            "Adding bpemb 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for transformers==2.5.1\n",
            "Best match: transformers 2.5.1\n",
            "Adding transformers 2.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for hyperopt==0.1.2\n",
            "Best match: hyperopt 0.1.2\n",
            "Adding hyperopt 0.1.2 to easy-install.pth file\n",
            "Installing hyperopt-mongo-worker script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Deprecated==1.2.7\n",
            "Best match: Deprecated 1.2.7\n",
            "Adding Deprecated 1.2.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for sqlitedict==1.6.0\n",
            "Best match: sqlitedict 1.6.0\n",
            "Adding sqlitedict 1.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.22.1\n",
            "Best match: scikit-learn 0.22.1\n",
            "Adding scikit-learn 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for mpld3==0.3\n",
            "Best match: mpld3 0.3\n",
            "Adding mpld3 0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.1.3\n",
            "Best match: matplotlib 3.1.3\n",
            "Adding matplotlib 3.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for segtok==1.5.7\n",
            "Best match: segtok 1.5.7\n",
            "Adding segtok 1.5.7 to easy-install.pth file\n",
            "Installing segmenter script to /usr/local/bin\n",
            "Installing tokenizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tqdm==4.28.1\n",
            "Best match: tqdm 4.28.1\n",
            "Adding tqdm 4.28.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytest==5.3.5\n",
            "Best match: pytest 5.3.5\n",
            "Adding pytest 5.3.5 to easy-install.pth file\n",
            "Installing py.test script to /usr/local/bin\n",
            "Installing pytest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gensim==3.6.0\n",
            "Best match: gensim 3.6.0\n",
            "Adding gensim 3.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.4.0\n",
            "Best match: torch 1.4.0\n",
            "Adding torch 1.4.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.6.1\n",
            "Best match: python-dateutil 2.6.1\n",
            "Adding python-dateutil 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.21.0\n",
            "Best match: requests 2.21.0\n",
            "Adding requests 2.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for sentencepiece==0.1.85\n",
            "Best match: sentencepiece 0.1.85\n",
            "Adding sentencepiece 0.1.85 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for filelock==3.0.12\n",
            "Best match: filelock 3.0.12\n",
            "Adding filelock 3.0.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tokenizers==0.5.2\n",
            "Best match: tokenizers 0.5.2\n",
            "Adding tokenizers 0.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for sacremoses==0.0.38\n",
            "Best match: sacremoses 0.0.38\n",
            "Adding sacremoses 0.0.38 to easy-install.pth file\n",
            "Installing sacremoses script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for boto3==1.11.15\n",
            "Best match: boto3 1.11.15\n",
            "Adding boto3 1.11.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pymongo==3.10.1\n",
            "Best match: pymongo 3.10.1\n",
            "Adding pymongo 3.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for networkx==2.4\n",
            "Best match: networkx 2.4\n",
            "Adding networkx 2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.11.2\n",
            "Best match: wrapt 1.11.2\n",
            "Adding wrapt 1.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.6\n",
            "Best match: pyparsing 2.4.6\n",
            "Adding pyparsing 2.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.1.0\n",
            "Best match: kiwisolver 1.1.0\n",
            "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pluggy==0.13.1\n",
            "Best match: pluggy 0.13.1\n",
            "Adding pluggy 0.13.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for attrs==19.3.0\n",
            "Best match: attrs 19.3.0\n",
            "Adding attrs 19.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for py==1.8.1\n",
            "Best match: py 1.8.1\n",
            "Adding py 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for importlib-metadata==1.5.0\n",
            "Best match: importlib-metadata 1.5.0\n",
            "Adding importlib-metadata 1.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for more-itertools==8.2.0\n",
            "Best match: more-itertools 8.2.0\n",
            "Adding more-itertools 8.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for packaging==20.1\n",
            "Best match: packaging 20.1\n",
            "Adding packaging 20.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wcwidth==0.1.8\n",
            "Best match: wcwidth 0.1.8\n",
            "Adding wcwidth 0.1.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for smart-open==1.9.0\n",
            "Best match: smart-open 1.9.0\n",
            "Adding smart-open 1.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.8\n",
            "Best match: idna 2.8\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2019.11.28\n",
            "Best match: certifi 2019.11.28\n",
            "Adding certifi 2019.11.28 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Click==7.0\n",
            "Best match: Click 7.0\n",
            "Adding Click 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for botocore==1.14.15\n",
            "Best match: botocore 1.14.15\n",
            "Adding botocore 1.14.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for jmespath==0.9.4\n",
            "Best match: jmespath 0.9.4\n",
            "Adding jmespath 0.9.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for s3transfer==0.3.3\n",
            "Best match: s3transfer 0.3.3\n",
            "Adding s3transfer 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for decorator==4.4.1\n",
            "Best match: decorator 4.4.1\n",
            "Adding decorator 4.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==45.2.0\n",
            "Best match: setuptools 45.2.0\n",
            "Adding setuptools 45.2.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for zipp==3.1.0\n",
            "Best match: zipp 3.1.0\n",
            "Adding zipp 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for boto==2.49.0\n",
            "Best match: boto 2.49.0\n",
            "Adding boto 2.49.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for docutils==0.15.2\n",
            "Best match: docutils 0.15.2\n",
            "Adding docutils 0.15.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for flair==0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43LT1wrUtCap"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0L-4FnwAQ6C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdSbj19T4T6l",
        "outputId": "43865d67-9420-4d73-8593-5fa4d3724810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/' ,force_remount=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AEj1TAjKBK_aoc6p2uexGokCE1M5WcmOCq0vHGSujsONTqu5ZKRuJA\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhvfsPLLQznL",
        "outputId": "4984d37a-04bc-4794-87ed-0e9485b81df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.bin.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-21 20:05:50--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4b8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4500982519 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.ar.300.bin.gz’\n",
            "\n",
            "cc.ar.300.bin.gz    100%[===================>]   4.19G  32.6MB/s    in 3m 11s  \n",
            "\n",
            "2020-04-21 20:09:02 (22.4 MB/s) - ‘cc.ar.300.bin.gz’ saved [4500982519/4500982519]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cD4PSHJSMD5"
      },
      "source": [
        "!gunzip cc.ar.300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NysCZ8_Uc5o",
        "outputId": "5a21fac8-f83d-4d15-84f9-dfad011c8079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd 'content/gdrive/My Drive/resources/tasks/conll_03/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/resources/tasks/conll_03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqdwpscgmWlX",
        "outputId": "f3e313df-793a-4a91-9656-3aff834aa9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/' )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uxShn-1odMM",
        "outputId": "4d7f78aa-8294-43bd-e3aa-1126b5ea1078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroA4a5qoe95",
        "outputId": "de9e536e-ddde-4584-f319-337df0c308cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DLZUU5vojkD",
        "outputId": "4e857389-5237-4740-f5e4-e1651d0c9cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install nltk "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVjrszBwRNSh",
        "outputId": "0015e2f1-d6f9-470c-fa0e-577bb30057db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.5)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.14.15)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo_rkM7doh5q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTnIPBR9UBdp",
        "outputId": "e3fed8f1-2d33-4246-c9f5-3ac903d74be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from flair.data import Corpus\n",
        "import gensim\n",
        "\n",
        "from flair.embeddings import FastTextEmbeddings,TokenEmbeddings, CharacterEmbeddings,  WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings,FlairEmbeddings,DocumentPoolEmbeddings\n",
        "from typing import List\n",
        "from flair.data import Dictionary\n",
        "from flair.models import LanguageModel\n",
        "from flair.trainers.language_model_trainer import LanguageModelTrainer, TextCorpus\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import BertEmbeddings\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk import ngrams\n",
        "\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/gdrive/My Drive/resources/tasks/conll_03'\n",
        "#data_folder = '/content/gdrive/My Drive/conll_03'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='ANERCorp.txt',\n",
        "                              test_file='ANERCorpdev.txt',\n",
        "                              dev_file='ANERCorptest.txt')\n",
        "    \n",
        "\n",
        "# 2. what tag do we want to predict?\n",
        "tag_type = 'ner'\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "#pooling_operation= 'mean' ,layers= '-1,-2\n",
        "#t_model = gensim.models.Word2Vec.load('models/full_grams_cbow_100_twitter.mdl')\n",
        "#custom_embedding = WordEmbeddings('path/to/your/custom/embeddings.gensim')\n",
        "#word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/path/to/fasttext/embeddings.txt', binary=False)\n",
        "#word_vectors.save('/path/to/converted')\n",
        "#char_lm_embeddings = FlairEmbeddings('resources/taggers/language_model/best-lm.pt')\n",
        "# initialize embeddings\n",
        "\"\"\"\n",
        "aravec = gensim.models.Word2Vec.load(data_folder+'/full_grams_cbow_300_wiki.mdl')\n",
        "aravec.load_word2vec_format.save(data_folder)\n",
        "\"\"\"\n",
        "\n",
        "#word_vectors = gensim.models.KeyedVectors.load_word2vec_format(data_folder+'/full_grams_cbow_300_wiki.mdl', binary=False)\n",
        "#word_vectors.save(data_folder)\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "\n",
        "    # fastext embeddings\n",
        "    #WordEmbeddings(data_folder+'/model.bin',True),\n",
        "    #WordEmbeddings(data_folder+'/full_grams_cbow_300_wiki.mdl'),\n",
        "    #BertEmbeddings('bert-base-multilingual-cased'),\n",
        "    #WordEmbeddings( data_folder+'/modelsg300wiki.gensim', 'custom'),\n",
        "    #CharacterEmbeddings(path_to_char_dict=data_folder+'/pytorch_model.bin',True)\n",
        "    #BertEmbeddings(bert_model_or_path = data_folder+'/config.json', data_folder+'/pytorch_model.bin' ,  data_folder+'/vocab.txt'), \n",
        "    #BertEmbeddings(bert_model_or_path = data_folder),\n",
        "    #flair fast embedding \n",
        "    WordEmbeddings('ar'),\n",
        "  \n",
        "\n",
        "    # orignal fast embeddings  from face\n",
        "    #FastTextEmbeddings(data_folder+'/fasttext300.bin'),\n",
        "    # BytePairEmbeddings('multi'),\n",
        "    # contextual string embeddings, forward\n",
        "    PooledFlairEmbeddings('ar-forward',  pooling= 'mean'),\n",
        "    # contextual string embeddings, backward\n",
        "    PooledFlairEmbeddings('ar-backward' ,  pooling= 'mean'),\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "#embeddings = DocumentPoolEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type  )\n",
        "\"\"\"tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type  ).load()\"\"\"\n",
        "# initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "from torch.optim.adam import Adam\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "                                        \n",
        "                            \n",
        "import pickle\n",
        "\n",
        "\n",
        "#checkpoint = '/content/gdrive/My Drive/resources/taggers/example-ner/checkpoint.pt'\n",
        "#from pathlib import Path\n",
        "#trainer = ModelTrainer.load_checkpoint(checkpoint, corpus)\n",
        "\n",
        "trainer.train('/content/gdrive/My Drive/resources/taggers/example-ner',\n",
        "              train_with_dev=True, \n",
        "              learning_rate=0.1,   \n",
        "              mini_batch_size=16,\n",
        "              max_epochs=150,\n",
        "              checkpoint=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-10 19:52:03,447 Reading data from /content/gdrive/My Drive/resources/tasks/conll_03\n",
            "2020-09-10 19:52:03,449 Train: /content/gdrive/My Drive/resources/tasks/conll_03/ANERCorp.txt\n",
            "2020-09-10 19:52:03,452 Dev: /content/gdrive/My Drive/resources/tasks/conll_03/ANERCorptest.txt\n",
            "2020-09-10 19:52:03,453 Test: /content/gdrive/My Drive/resources/tasks/conll_03/ANERCorpdev.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-09-10 19:52:09,275 ----------------------------------------------------------------------------------------------------\n",
            "2020-09-10 19:52:09,277 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('ar')\n",
            "    (list_embedding_1): PooledFlairEmbeddings(\n",
            "      (context_embeddings): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "          (encoder): Embedding(7125, 100)\n",
            "          (rnn): LSTM(100, 2048)\n",
            "          (decoder): Linear(in_features=2048, out_features=7125, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): PooledFlairEmbeddings(\n",
            "      (context_embeddings): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "          (encoder): Embedding(7125, 100)\n",
            "          (rnn): LSTM(100, 2048)\n",
            "          (decoder): Linear(in_features=2048, out_features=7125, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=8492, out_features=8492, bias=True)\n",
            "  (rnn): LSTM(8492, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-09-10 19:52:09,279 ----------------------------------------------------------------------------------------------------\n",
            "2020-09-10 19:52:09,281 Corpus: \"Corpus: 1 train + 1 dev + 1 test sentences\"\n",
            "2020-09-10 19:52:09,283 ----------------------------------------------------------------------------------------------------\n",
            "2020-09-10 19:52:09,284 Parameters:\n",
            "2020-09-10 19:52:09,286  - learning_rate: \"0.1\"\n",
            "2020-09-10 19:52:09,288  - mini_batch_size: \"16\"\n",
            "2020-09-10 19:52:09,289  - patience: \"3\"\n",
            "2020-09-10 19:52:09,291  - anneal_factor: \"0.5\"\n",
            "2020-09-10 19:52:09,293  - max_epochs: \"150\"\n",
            "2020-09-10 19:52:09,295  - shuffle: \"True\"\n",
            "2020-09-10 19:52:09,296  - train_with_dev: \"True\"\n",
            "2020-09-10 19:52:09,300  - batch_growth_annealing: \"False\"\n",
            "2020-09-10 19:52:09,301 ----------------------------------------------------------------------------------------------------\n",
            "2020-09-10 19:52:09,303 Model training base path: \"/content/gdrive/My Drive/resources/taggers/example-ner\"\n",
            "2020-09-10 19:52:09,304 ----------------------------------------------------------------------------------------------------\n",
            "2020-09-10 19:52:09,307 Device: cuda:0\n",
            "2020-09-10 19:52:09,308 ----------------------------------------------------------------------------------------------------\n",
            "2020-09-10 19:52:09,309 Embeddings storage mode: cpu\n",
            "2020-09-10 19:52:09,317 ----------------------------------------------------------------------------------------------------\n",
            "train mode resetting embeddings\n",
            "train mode resetting embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c3d23d042249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m               \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m               \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m               checkpoint=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, scheduler, cycle_momentum, anneal_factor, patience, initial_extra_patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                         \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, data_points, sort)\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     ) -> torch.tensor:\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;31m# if we keep a pooling, it needs to be updated continuously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             all_hidden_states_in_lm = self.lm.get_representation(\n\u001b[0;32m--> 610\u001b[0;31m                 \u001b[0mtext_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_per_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m             )\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, start_marker, end_marker, chars_per_chunk)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0moutput_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 577\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 15.90 GiB total capacity; 13.27 GiB already allocated; 9.88 MiB free; 15.02 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qIZ5ofAeR_6",
        "outputId": "e9f0dab3-36b8-43d5-e54e-1a8d44dc85d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWKG4LYfNu-D",
        "outputId": "c55e4d55-3fc4-47d9-e7ba-9881fa06f121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (45.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnEUBWEG086n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOlVhB0Xq7fJ",
        "outputId": "e4950999-f4c8-48ec-9430-8af159d0ceea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import CONLL_03\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
        "from typing import List\n",
        "from flair.data import Dictionary\n",
        "from flair.models import LanguageModel\n",
        "from flair.trainers.language_model_trainer import LanguageModelTrainer, TextCorpus\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/gdrive/My Drive/resources/tasks/conll_03'\n",
        "#data_folder = '/content/gdrive/My Drive/conll_03'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "    \n",
        "\n",
        "\n",
        "# initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "checkpoint = '/content/gdrive/My Drive/resources/taggers/example-ner/checkpoint.pt'\n",
        "from pathlib import Path\n",
        "from torch.optim.adam import Adam\n",
        "trainer = ModelTrainer.load_checkpoint(checkpoint, corpus)\n",
        "\n",
        "trainer.train('/content/gdrive/My Drive/resources/taggers/example-ner',\n",
        "              train_with_dev=True, \n",
        "              learning_rate=0.1,   \n",
        "              mini_batch_size=16,\n",
        "              max_epochs=150,\n",
        "              checkpoint=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-14 07:40:22,615 Reading data from /content/gdrive/My Drive/resources/tasks/conll_03\n",
            "2020-07-14 07:40:22,616 Train: /content/gdrive/My Drive/resources/tasks/conll_03/train.txt\n",
            "2020-07-14 07:40:22,616 Dev: /content/gdrive/My Drive/resources/tasks/conll_03/dev.txt\n",
            "2020-07-14 07:40:22,617 Test: /content/gdrive/My Drive/resources/tasks/conll_03/test.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dc8cf470267c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m trainer.train('/content/gdrive/My Drive/resources/taggers/example-ner',\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(cls, checkpoint, corpus)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelTrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \"functionality.\".format(type(f)))\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sssz7M1BUGpX"
      },
      "source": [
        "pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNi-NBsjBNX1"
      },
      "source": [
        "# HyperParamters Optimatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm8B2OSyZm9U",
        "outputId": "879a76ca-1613-4a3f-bbdb-dc93dcf11cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "from hyperopt import hp\n",
        "from flair.hyperparameter.param_selection import SearchSpace, Parameter\n",
        "\n",
        "# define your search space\n",
        "search_space = SearchSpace()\n",
        "search_space.add(Parameter.EMBEDDINGS, hp.choice, options=[\n",
        "    [ WordEmbeddings('ar') ], \n",
        "    [ FlairEmbeddings('ar-forward'), FlairEmbeddings('ar-backward') ]\n",
        "])\n",
        "search_space.add(Parameter.HIDDEN_SIZE, hp.choice, options=[32, 64, 128])\n",
        "search_space.add(Parameter.RNN_LAYERS, hp.choice, options=[1, 2])\n",
        "search_space.add(Parameter.DROPOUT, hp.uniform, low=0.0, high=0.5)\n",
        "search_space.add(Parameter.LEARNING_RATE, hp.choice, options=[0.05, 0.1, 0.15, 0.2])\n",
        "search_space.add(Parameter.MINI_BATCH_SIZE, hp.choice, options=[8, 16, 32])\n",
        "\n",
        "search_space.add(Parameter.EMBEDDINGS, hp.choice, options=[\n",
        "    [ FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward') ]\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-11 00:23:48,053 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpattuarux\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:03<00:00, 18905783.97B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-11 00:23:52,513 copying /tmp/tmpattuarux to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-11 00:23:52,680 removing temp file /tmp/tmpattuarux\n",
            "2020-02-11 00:23:53,429 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpvz3pptjo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034575/73034575 [00:04<00:00, 15303534.37B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-11 00:23:58,760 copying /tmp/tmpvz3pptjo to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-11 00:23:58,920 removing temp file /tmp/tmpvz3pptjo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS09Mb7YDzPZ",
        "outputId": "380e2074-ca06-4896-c5f9-51ea6e3f3baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer.train('/content/gdrive/My Drive/resources/taggers/example-ner',\n",
        "              train_with_dev=True, \n",
        "              learning_rate=0.1,   \n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150,\n",
        "              )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-03 17:27:52,814 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:52,819 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('ar')\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (encoder): Embedding(7125, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=7125, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (encoder): Embedding(7125, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=7125, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
            "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-03 17:27:52,821 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:52,823 Corpus: \"Corpus: 1328 train + 710 dev + 605 test sentences\"\n",
            "2020-02-03 17:27:52,826 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:52,828 Parameters:\n",
            "2020-02-03 17:27:52,830  - learning_rate: \"0.1\"\n",
            "2020-02-03 17:27:52,832  - mini_batch_size: \"32\"\n",
            "2020-02-03 17:27:52,834  - patience: \"3\"\n",
            "2020-02-03 17:27:52,836  - anneal_factor: \"0.5\"\n",
            "2020-02-03 17:27:52,839  - max_epochs: \"150\"\n",
            "2020-02-03 17:27:52,841  - shuffle: \"True\"\n",
            "2020-02-03 17:27:52,843  - train_with_dev: \"True\"\n",
            "2020-02-03 17:27:52,845  - batch_growth_annealing: \"False\"\n",
            "2020-02-03 17:27:52,847 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:52,849 Model training base path: \"/content/gdrive/My Drive/resources/taggers/example-ner\"\n",
            "2020-02-03 17:27:52,851 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:52,853 Device: cuda:0\n",
            "2020-02-03 17:27:52,855 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:52,858 Embeddings storage mode: cpu\n",
            "2020-02-03 17:27:52,898 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:27:55,407 epoch 10 - iter 6/64 - loss 2.82702927 - samples/sec: 76.62\n",
            "2020-02-03 17:27:58,361 epoch 10 - iter 12/64 - loss 2.80625610 - samples/sec: 121.31\n",
            "2020-02-03 17:28:01,003 epoch 10 - iter 18/64 - loss 2.76697253 - samples/sec: 135.17\n",
            "2020-02-03 17:28:04,142 epoch 10 - iter 24/64 - loss 2.63071097 - samples/sec: 105.20\n",
            "2020-02-03 17:28:07,004 epoch 10 - iter 30/64 - loss 2.59797289 - samples/sec: 110.15\n",
            "2020-02-03 17:28:10,032 epoch 10 - iter 36/64 - loss 3.26560847 - samples/sec: 105.26\n",
            "2020-02-03 17:28:13,006 epoch 10 - iter 42/64 - loss 3.29688096 - samples/sec: 108.94\n",
            "2020-02-03 17:28:16,199 epoch 10 - iter 48/64 - loss 3.24917267 - samples/sec: 96.82\n",
            "2020-02-03 17:28:19,224 epoch 10 - iter 54/64 - loss 3.22922820 - samples/sec: 100.39\n",
            "2020-02-03 17:28:22,262 epoch 10 - iter 60/64 - loss 3.18066892 - samples/sec: 110.92\n",
            "2020-02-03 17:28:24,557 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:28:24,559 EPOCH 10 done: loss 3.1728 - lr 0.1000\n",
            "2020-02-03 17:28:24,564 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:28:24,570 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:28:26,328 epoch 11 - iter 6/64 - loss 2.82839000 - samples/sec: 109.37\n",
            "2020-02-03 17:28:29,241 epoch 11 - iter 12/64 - loss 2.81582885 - samples/sec: 107.14\n",
            "2020-02-03 17:28:32,765 epoch 11 - iter 18/64 - loss 2.82585012 - samples/sec: 84.47\n",
            "2020-02-03 17:28:35,952 epoch 11 - iter 24/64 - loss 2.81061232 - samples/sec: 101.24\n",
            "2020-02-03 17:28:38,502 epoch 11 - iter 30/64 - loss 2.65149810 - samples/sec: 142.42\n",
            "2020-02-03 17:28:41,220 epoch 11 - iter 36/64 - loss 2.60991426 - samples/sec: 127.34\n",
            "2020-02-03 17:28:44,200 epoch 11 - iter 42/64 - loss 2.59978945 - samples/sec: 108.31\n",
            "2020-02-03 17:28:47,666 epoch 11 - iter 48/64 - loss 2.57081733 - samples/sec: 93.82\n",
            "2020-02-03 17:28:50,480 epoch 11 - iter 54/64 - loss 2.54774301 - samples/sec: 118.64\n",
            "2020-02-03 17:28:53,918 epoch 11 - iter 60/64 - loss 2.89617088 - samples/sec: 89.99\n",
            "2020-02-03 17:28:56,442 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:28:56,444 EPOCH 11 done: loss 2.8621 - lr 0.1000\n",
            "2020-02-03 17:28:56,446 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:28:56,455 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:28:58,361 epoch 12 - iter 6/64 - loss 2.16560362 - samples/sec: 100.99\n",
            "2020-02-03 17:29:01,431 epoch 12 - iter 12/64 - loss 2.30146391 - samples/sec: 97.83\n",
            "2020-02-03 17:29:04,422 epoch 12 - iter 18/64 - loss 2.24571502 - samples/sec: 107.90\n",
            "2020-02-03 17:29:07,384 epoch 12 - iter 24/64 - loss 2.38458851 - samples/sec: 103.28\n",
            "2020-02-03 17:29:10,372 epoch 12 - iter 30/64 - loss 2.43604191 - samples/sec: 113.73\n",
            "2020-02-03 17:29:13,217 epoch 12 - iter 36/64 - loss 2.57305709 - samples/sec: 116.89\n",
            "2020-02-03 17:29:16,680 epoch 12 - iter 42/64 - loss 3.01326394 - samples/sec: 85.42\n",
            "2020-02-03 17:29:19,728 epoch 12 - iter 48/64 - loss 2.95495753 - samples/sec: 112.28\n",
            "2020-02-03 17:29:22,780 epoch 12 - iter 54/64 - loss 2.88793521 - samples/sec: 109.96\n",
            "2020-02-03 17:29:25,644 epoch 12 - iter 60/64 - loss 2.81880725 - samples/sec: 130.17\n",
            "2020-02-03 17:29:27,903 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:29:27,905 EPOCH 12 done: loss 2.8188 - lr 0.1000\n",
            "2020-02-03 17:29:27,907 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:29:27,911 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:29:29,379 epoch 13 - iter 6/64 - loss 2.14099993 - samples/sec: 131.08\n",
            "2020-02-03 17:29:32,480 epoch 13 - iter 12/64 - loss 2.12689307 - samples/sec: 96.45\n",
            "2020-02-03 17:29:35,519 epoch 13 - iter 18/64 - loss 2.22977910 - samples/sec: 103.88\n",
            "2020-02-03 17:29:38,390 epoch 13 - iter 24/64 - loss 2.19601658 - samples/sec: 114.58\n",
            "2020-02-03 17:29:41,366 epoch 13 - iter 30/64 - loss 2.31170956 - samples/sec: 108.69\n",
            "2020-02-03 17:29:44,741 epoch 13 - iter 36/64 - loss 2.36725894 - samples/sec: 88.48\n",
            "2020-02-03 17:29:47,925 epoch 13 - iter 42/64 - loss 2.39284830 - samples/sec: 116.63\n",
            "2020-02-03 17:29:51,284 epoch 13 - iter 48/64 - loss 2.76633633 - samples/sec: 93.12\n",
            "2020-02-03 17:29:54,364 epoch 13 - iter 54/64 - loss 2.71729054 - samples/sec: 115.01\n",
            "2020-02-03 17:29:57,594 epoch 13 - iter 60/64 - loss 2.68134075 - samples/sec: 99.97\n",
            "2020-02-03 17:30:00,052 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:30:00,057 EPOCH 13 done: loss 2.6827 - lr 0.1000\n",
            "2020-02-03 17:30:00,059 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:30:00,068 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:30:01,729 epoch 14 - iter 6/64 - loss 2.22386843 - samples/sec: 115.81\n",
            "2020-02-03 17:30:04,979 epoch 14 - iter 12/64 - loss 2.68383828 - samples/sec: 98.76\n",
            "2020-02-03 17:30:07,993 epoch 14 - iter 18/64 - loss 2.38215901 - samples/sec: 109.11\n",
            "2020-02-03 17:30:11,059 epoch 14 - iter 24/64 - loss 2.28669596 - samples/sec: 108.43\n",
            "2020-02-03 17:30:14,971 epoch 14 - iter 30/64 - loss 2.32306811 - samples/sec: 73.77\n",
            "2020-02-03 17:30:18,272 epoch 14 - iter 36/64 - loss 2.95599551 - samples/sec: 96.75\n",
            "2020-02-03 17:30:21,119 epoch 14 - iter 42/64 - loss 2.86873227 - samples/sec: 110.58\n",
            "2020-02-03 17:30:24,515 epoch 14 - iter 48/64 - loss 2.82656410 - samples/sec: 107.53\n",
            "2020-02-03 17:30:28,123 epoch 14 - iter 54/64 - loss 2.74631591 - samples/sec: 87.50\n",
            "2020-02-03 17:30:31,455 epoch 14 - iter 60/64 - loss 2.68736455 - samples/sec: 99.83\n",
            "2020-02-03 17:30:33,868 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:30:33,872 EPOCH 14 done: loss 2.6686 - lr 0.1000\n",
            "2020-02-03 17:30:33,876 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:30:33,881 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:30:35,352 epoch 15 - iter 6/64 - loss 1.97729222 - samples/sec: 130.99\n",
            "2020-02-03 17:30:38,001 epoch 15 - iter 12/64 - loss 2.29158077 - samples/sec: 116.50\n",
            "2020-02-03 17:30:41,169 epoch 15 - iter 18/64 - loss 2.25194942 - samples/sec: 102.72\n",
            "2020-02-03 17:30:43,908 epoch 15 - iter 24/64 - loss 2.24276016 - samples/sec: 125.71\n",
            "2020-02-03 17:30:47,257 epoch 15 - iter 30/64 - loss 2.18195651 - samples/sec: 95.48\n",
            "2020-02-03 17:30:50,505 epoch 15 - iter 36/64 - loss 2.69884916 - samples/sec: 98.69\n",
            "2020-02-03 17:30:54,283 epoch 15 - iter 42/64 - loss 2.60937007 - samples/sec: 77.89\n",
            "2020-02-03 17:30:57,491 epoch 15 - iter 48/64 - loss 2.52614640 - samples/sec: 102.71\n",
            "2020-02-03 17:31:00,494 epoch 15 - iter 54/64 - loss 2.50670705 - samples/sec: 107.89\n",
            "2020-02-03 17:31:03,302 epoch 15 - iter 60/64 - loss 2.46072449 - samples/sec: 120.24\n",
            "2020-02-03 17:31:05,627 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:31:05,630 EPOCH 15 done: loss 2.4738 - lr 0.1000\n",
            "2020-02-03 17:31:05,632 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:31:05,636 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:31:07,266 epoch 16 - iter 6/64 - loss 2.03976981 - samples/sec: 118.22\n",
            "2020-02-03 17:31:10,511 epoch 16 - iter 12/64 - loss 3.05232452 - samples/sec: 93.93\n",
            "2020-02-03 17:31:13,523 epoch 16 - iter 18/64 - loss 2.88840378 - samples/sec: 107.06\n",
            "2020-02-03 17:31:16,713 epoch 16 - iter 24/64 - loss 2.71146287 - samples/sec: 101.38\n",
            "2020-02-03 17:31:19,904 epoch 16 - iter 30/64 - loss 2.57633071 - samples/sec: 108.29\n",
            "2020-02-03 17:31:23,071 epoch 16 - iter 36/64 - loss 2.51658351 - samples/sec: 102.95\n",
            "2020-02-03 17:31:26,130 epoch 16 - iter 42/64 - loss 2.43626133 - samples/sec: 109.29\n",
            "2020-02-03 17:31:29,246 epoch 16 - iter 48/64 - loss 2.41993175 - samples/sec: 100.15\n",
            "2020-02-03 17:31:32,445 epoch 16 - iter 54/64 - loss 2.33946502 - samples/sec: 96.50\n",
            "2020-02-03 17:31:35,538 epoch 16 - iter 60/64 - loss 2.32953317 - samples/sec: 102.18\n",
            "2020-02-03 17:31:37,828 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:31:37,833 EPOCH 16 done: loss 2.3082 - lr 0.1000\n",
            "2020-02-03 17:31:37,836 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:31:37,841 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:31:39,658 epoch 17 - iter 6/64 - loss 1.58376878 - samples/sec: 105.86\n",
            "2020-02-03 17:31:42,458 epoch 17 - iter 12/64 - loss 1.78667306 - samples/sec: 129.73\n",
            "2020-02-03 17:31:45,614 epoch 17 - iter 18/64 - loss 1.74098116 - samples/sec: 95.80\n",
            "2020-02-03 17:31:48,763 epoch 17 - iter 24/64 - loss 1.87966619 - samples/sec: 118.77\n",
            "2020-02-03 17:31:51,664 epoch 17 - iter 30/64 - loss 1.77699968 - samples/sec: 119.34\n",
            "2020-02-03 17:31:55,115 epoch 17 - iter 36/64 - loss 2.34992771 - samples/sec: 91.22\n",
            "2020-02-03 17:31:58,300 epoch 17 - iter 42/64 - loss 2.28074444 - samples/sec: 96.72\n",
            "2020-02-03 17:32:01,366 epoch 17 - iter 48/64 - loss 2.26260066 - samples/sec: 102.35\n",
            "2020-02-03 17:32:04,565 epoch 17 - iter 54/64 - loss 2.24002899 - samples/sec: 97.09\n",
            "2020-02-03 17:32:07,910 epoch 17 - iter 60/64 - loss 2.24795704 - samples/sec: 105.08\n",
            "2020-02-03 17:32:10,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:32:10,255 EPOCH 17 done: loss 2.2218 - lr 0.1000\n",
            "2020-02-03 17:32:10,257 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:32:10,262 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:32:12,195 epoch 18 - iter 6/64 - loss 2.00777566 - samples/sec: 99.48\n",
            "2020-02-03 17:32:14,852 epoch 18 - iter 12/64 - loss 1.85285564 - samples/sec: 132.15\n",
            "2020-02-03 17:32:18,477 epoch 18 - iter 18/64 - loss 1.92878485 - samples/sec: 86.69\n",
            "2020-02-03 17:32:21,224 epoch 18 - iter 24/64 - loss 1.93248969 - samples/sec: 117.78\n",
            "2020-02-03 17:32:24,514 epoch 18 - iter 30/64 - loss 1.97085158 - samples/sec: 96.36\n",
            "2020-02-03 17:32:27,424 epoch 18 - iter 36/64 - loss 1.94241608 - samples/sec: 113.00\n",
            "2020-02-03 17:32:30,442 epoch 18 - iter 42/64 - loss 1.92998557 - samples/sec: 120.09\n",
            "2020-02-03 17:32:33,431 epoch 18 - iter 48/64 - loss 1.89812917 - samples/sec: 113.60\n",
            "2020-02-03 17:32:36,774 epoch 18 - iter 54/64 - loss 2.36462756 - samples/sec: 96.23\n",
            "2020-02-03 17:32:39,560 epoch 18 - iter 60/64 - loss 2.31567795 - samples/sec: 121.80\n",
            "2020-02-03 17:32:42,048 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:32:42,050 EPOCH 18 done: loss 2.2755 - lr 0.1000\n",
            "2020-02-03 17:32:42,052 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:32:42,065 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:32:43,863 epoch 19 - iter 6/64 - loss 1.56593959 - samples/sec: 107.07\n",
            "2020-02-03 17:32:47,389 epoch 19 - iter 12/64 - loss 1.58198502 - samples/sec: 90.43\n",
            "2020-02-03 17:32:49,872 epoch 19 - iter 18/64 - loss 1.55588358 - samples/sec: 149.24\n",
            "2020-02-03 17:32:53,066 epoch 19 - iter 24/64 - loss 1.57174298 - samples/sec: 101.68\n",
            "2020-02-03 17:32:56,022 epoch 19 - iter 30/64 - loss 1.64119796 - samples/sec: 116.33\n",
            "2020-02-03 17:32:59,435 epoch 19 - iter 36/64 - loss 1.66748956 - samples/sec: 91.45\n",
            "2020-02-03 17:33:02,532 epoch 19 - iter 42/64 - loss 2.11148770 - samples/sec: 106.67\n",
            "2020-02-03 17:33:05,495 epoch 19 - iter 48/64 - loss 2.06904233 - samples/sec: 109.38\n",
            "2020-02-03 17:33:08,809 epoch 19 - iter 54/64 - loss 2.06884039 - samples/sec: 95.25\n",
            "2020-02-03 17:33:11,770 epoch 19 - iter 60/64 - loss 2.04139624 - samples/sec: 108.58\n",
            "2020-02-03 17:33:14,155 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:33:14,157 EPOCH 19 done: loss 2.0287 - lr 0.1000\n",
            "2020-02-03 17:33:14,159 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:33:14,164 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:33:15,903 epoch 20 - iter 6/64 - loss 1.59132471 - samples/sec: 110.55\n",
            "2020-02-03 17:33:19,069 epoch 20 - iter 12/64 - loss 1.89340305 - samples/sec: 102.77\n",
            "2020-02-03 17:33:21,646 epoch 20 - iter 18/64 - loss 1.78375614 - samples/sec: 139.37\n",
            "2020-02-03 17:33:24,738 epoch 20 - iter 24/64 - loss 1.77761088 - samples/sec: 97.14\n",
            "2020-02-03 17:33:27,633 epoch 20 - iter 30/64 - loss 1.73657170 - samples/sec: 110.14\n",
            "2020-02-03 17:33:31,037 epoch 20 - iter 36/64 - loss 2.47823656 - samples/sec: 91.31\n",
            "2020-02-03 17:33:34,169 epoch 20 - iter 42/64 - loss 2.37321762 - samples/sec: 99.64\n",
            "2020-02-03 17:33:37,159 epoch 20 - iter 48/64 - loss 2.30942559 - samples/sec: 107.73\n",
            "2020-02-03 17:33:40,049 epoch 20 - iter 54/64 - loss 2.22301000 - samples/sec: 120.88\n",
            "2020-02-03 17:33:43,513 epoch 20 - iter 60/64 - loss 2.17233860 - samples/sec: 88.79\n",
            "2020-02-03 17:33:46,119 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:33:46,121 EPOCH 20 done: loss 2.1644 - lr 0.1000\n",
            "2020-02-03 17:33:46,126 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:33:46,137 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:33:48,092 epoch 21 - iter 6/64 - loss 5.05506204 - samples/sec: 98.50\n",
            "2020-02-03 17:33:50,877 epoch 21 - iter 12/64 - loss 3.31252098 - samples/sec: 121.27\n",
            "2020-02-03 17:33:54,039 epoch 21 - iter 18/64 - loss 2.71819728 - samples/sec: 109.78\n",
            "2020-02-03 17:33:57,012 epoch 21 - iter 24/64 - loss 2.38494453 - samples/sec: 109.18\n",
            "2020-02-03 17:33:59,735 epoch 21 - iter 30/64 - loss 2.22312851 - samples/sec: 127.02\n",
            "2020-02-03 17:34:02,958 epoch 21 - iter 36/64 - loss 2.13800334 - samples/sec: 100.76\n",
            "2020-02-03 17:34:05,890 epoch 21 - iter 42/64 - loss 2.07674013 - samples/sec: 111.11\n",
            "2020-02-03 17:34:08,433 epoch 21 - iter 48/64 - loss 2.01383167 - samples/sec: 133.17\n",
            "2020-02-03 17:34:11,519 epoch 21 - iter 54/64 - loss 1.99108115 - samples/sec: 103.16\n",
            "2020-02-03 17:34:15,073 epoch 21 - iter 60/64 - loss 1.94441678 - samples/sec: 91.48\n",
            "2020-02-03 17:34:17,470 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:34:17,473 EPOCH 21 done: loss 1.9209 - lr 0.1000\n",
            "2020-02-03 17:34:17,475 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:34:17,480 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:34:19,259 epoch 22 - iter 6/64 - loss 1.95897565 - samples/sec: 108.12\n",
            "2020-02-03 17:34:22,592 epoch 22 - iter 12/64 - loss 1.90007639 - samples/sec: 94.21\n",
            "2020-02-03 17:34:25,616 epoch 22 - iter 18/64 - loss 1.70835961 - samples/sec: 111.24\n",
            "2020-02-03 17:34:28,381 epoch 22 - iter 24/64 - loss 1.61312145 - samples/sec: 123.69\n",
            "2020-02-03 17:34:31,237 epoch 22 - iter 30/64 - loss 1.62587044 - samples/sec: 116.52\n",
            "2020-02-03 17:34:34,105 epoch 22 - iter 36/64 - loss 2.21458747 - samples/sec: 108.84\n",
            "2020-02-03 17:34:36,992 epoch 22 - iter 42/64 - loss 2.17321258 - samples/sec: 114.19\n",
            "2020-02-03 17:34:39,993 epoch 22 - iter 48/64 - loss 2.06950717 - samples/sec: 112.54\n",
            "2020-02-03 17:34:43,243 epoch 22 - iter 54/64 - loss 2.01262439 - samples/sec: 94.10\n",
            "2020-02-03 17:34:46,822 epoch 22 - iter 60/64 - loss 1.95316088 - samples/sec: 88.54\n",
            "2020-02-03 17:34:49,247 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:34:49,249 EPOCH 22 done: loss 1.9390 - lr 0.1000\n",
            "2020-02-03 17:34:49,253 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:34:49,257 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:34:50,711 epoch 23 - iter 6/64 - loss 1.42007484 - samples/sec: 132.31\n",
            "2020-02-03 17:34:54,485 epoch 23 - iter 12/64 - loss 1.32469104 - samples/sec: 78.06\n",
            "2020-02-03 17:34:57,535 epoch 23 - iter 18/64 - loss 1.41478871 - samples/sec: 103.64\n",
            "2020-02-03 17:35:00,444 epoch 23 - iter 24/64 - loss 1.43248610 - samples/sec: 112.64\n",
            "2020-02-03 17:35:03,443 epoch 23 - iter 30/64 - loss 1.39433523 - samples/sec: 109.90\n",
            "2020-02-03 17:35:06,408 epoch 23 - iter 36/64 - loss 1.43538832 - samples/sec: 109.05\n",
            "2020-02-03 17:35:09,153 epoch 23 - iter 42/64 - loss 1.45594081 - samples/sec: 124.32\n",
            "2020-02-03 17:35:12,125 epoch 23 - iter 48/64 - loss 1.45454123 - samples/sec: 108.83\n",
            "2020-02-03 17:35:16,006 epoch 23 - iter 54/64 - loss 1.82346477 - samples/sec: 74.59\n",
            "2020-02-03 17:35:19,107 epoch 23 - iter 60/64 - loss 1.77252529 - samples/sec: 113.26\n",
            "2020-02-03 17:35:21,229 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:35:21,231 EPOCH 23 done: loss 1.7683 - lr 0.1000\n",
            "2020-02-03 17:35:21,234 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:35:21,240 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:35:23,275 epoch 24 - iter 6/64 - loss 4.60014914 - samples/sec: 94.44\n",
            "2020-02-03 17:35:26,141 epoch 24 - iter 12/64 - loss 3.02284858 - samples/sec: 116.78\n",
            "2020-02-03 17:35:29,151 epoch 24 - iter 18/64 - loss 2.47921768 - samples/sec: 113.89\n",
            "2020-02-03 17:35:31,765 epoch 24 - iter 24/64 - loss 2.13742197 - samples/sec: 126.74\n",
            "2020-02-03 17:35:35,434 epoch 24 - iter 30/64 - loss 1.97154216 - samples/sec: 89.42\n",
            "2020-02-03 17:35:38,620 epoch 24 - iter 36/64 - loss 1.97998912 - samples/sec: 97.66\n",
            "2020-02-03 17:35:41,855 epoch 24 - iter 42/64 - loss 1.86945352 - samples/sec: 100.05\n",
            "2020-02-03 17:35:44,890 epoch 24 - iter 48/64 - loss 1.79706209 - samples/sec: 105.19\n",
            "2020-02-03 17:35:47,957 epoch 24 - iter 54/64 - loss 1.76572828 - samples/sec: 116.43\n",
            "2020-02-03 17:35:50,968 epoch 24 - iter 60/64 - loss 1.73600271 - samples/sec: 106.47\n",
            "2020-02-03 17:35:53,739 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:35:53,745 EPOCH 24 done: loss 1.7306 - lr 0.1000\n",
            "2020-02-03 17:35:53,749 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:35:53,754 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:35:55,367 epoch 25 - iter 6/64 - loss 1.27824938 - samples/sec: 119.36\n",
            "2020-02-03 17:35:58,480 epoch 25 - iter 12/64 - loss 1.23437090 - samples/sec: 105.81\n",
            "2020-02-03 17:36:01,774 epoch 25 - iter 18/64 - loss 1.23742759 - samples/sec: 96.54\n",
            "2020-02-03 17:36:05,112 epoch 25 - iter 24/64 - loss 1.25260406 - samples/sec: 94.45\n",
            "2020-02-03 17:36:07,802 epoch 25 - iter 30/64 - loss 1.31219069 - samples/sec: 130.13\n",
            "2020-02-03 17:36:10,700 epoch 25 - iter 36/64 - loss 1.30635598 - samples/sec: 113.53\n",
            "2020-02-03 17:36:13,841 epoch 25 - iter 42/64 - loss 1.28210829 - samples/sec: 104.89\n",
            "2020-02-03 17:36:17,410 epoch 25 - iter 48/64 - loss 1.72039963 - samples/sec: 77.86\n",
            "2020-02-03 17:36:20,575 epoch 25 - iter 54/64 - loss 1.68687307 - samples/sec: 103.48\n",
            "2020-02-03 17:36:23,697 epoch 25 - iter 60/64 - loss 1.68277628 - samples/sec: 106.12\n",
            "2020-02-03 17:36:25,997 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:36:25,999 EPOCH 25 done: loss 1.6950 - lr 0.1000\n",
            "2020-02-03 17:36:26,001 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:36:26,008 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:36:27,894 epoch 26 - iter 6/64 - loss 1.40453305 - samples/sec: 102.10\n",
            "2020-02-03 17:36:30,841 epoch 26 - iter 12/64 - loss 2.20662962 - samples/sec: 116.81\n",
            "2020-02-03 17:36:34,101 epoch 26 - iter 18/64 - loss 1.96733779 - samples/sec: 98.26\n",
            "2020-02-03 17:36:37,153 epoch 26 - iter 24/64 - loss 1.86488306 - samples/sec: 110.43\n",
            "2020-02-03 17:36:39,913 epoch 26 - iter 30/64 - loss 1.75378213 - samples/sec: 115.81\n",
            "2020-02-03 17:36:42,795 epoch 26 - iter 36/64 - loss 1.68803141 - samples/sec: 124.48\n",
            "2020-02-03 17:36:46,615 epoch 26 - iter 42/64 - loss 1.64024428 - samples/sec: 71.09\n",
            "2020-02-03 17:36:49,474 epoch 26 - iter 48/64 - loss 1.62343037 - samples/sec: 117.16\n",
            "2020-02-03 17:36:52,620 epoch 26 - iter 54/64 - loss 1.59525239 - samples/sec: 104.43\n",
            "2020-02-03 17:36:55,811 epoch 26 - iter 60/64 - loss 1.58727391 - samples/sec: 101.63\n",
            "2020-02-03 17:36:58,310 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:36:58,312 EPOCH 26 done: loss 1.6183 - lr 0.1000\n",
            "2020-02-03 17:36:58,313 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:36:58,319 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:37:00,250 epoch 27 - iter 6/64 - loss 1.63719082 - samples/sec: 99.81\n",
            "2020-02-03 17:37:03,261 epoch 27 - iter 12/64 - loss 1.58720346 - samples/sec: 107.34\n",
            "2020-02-03 17:37:06,224 epoch 27 - iter 18/64 - loss 1.47623732 - samples/sec: 114.81\n",
            "2020-02-03 17:37:09,054 epoch 27 - iter 24/64 - loss 1.37381212 - samples/sec: 117.32\n",
            "2020-02-03 17:37:12,132 epoch 27 - iter 30/64 - loss 1.34686093 - samples/sec: 108.28\n",
            "2020-02-03 17:37:15,163 epoch 27 - iter 36/64 - loss 1.30644613 - samples/sec: 111.65\n",
            "2020-02-03 17:37:18,826 epoch 27 - iter 42/64 - loss 1.35177953 - samples/sec: 78.58\n",
            "2020-02-03 17:37:21,779 epoch 27 - iter 48/64 - loss 1.73600811 - samples/sec: 110.53\n",
            "2020-02-03 17:37:24,687 epoch 27 - iter 54/64 - loss 1.69477839 - samples/sec: 113.20\n",
            "2020-02-03 17:37:28,061 epoch 27 - iter 60/64 - loss 1.66311591 - samples/sec: 92.15\n",
            "2020-02-03 17:37:30,615 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:37:30,616 EPOCH 27 done: loss 1.6481 - lr 0.1000\n",
            "2020-02-03 17:37:30,618 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:37:30,625 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:37:32,518 epoch 28 - iter 6/64 - loss 1.41410394 - samples/sec: 101.64\n",
            "2020-02-03 17:37:36,020 epoch 28 - iter 12/64 - loss 2.14900508 - samples/sec: 83.44\n",
            "2020-02-03 17:37:38,616 epoch 28 - iter 18/64 - loss 1.89170394 - samples/sec: 137.04\n",
            "2020-02-03 17:37:41,630 epoch 28 - iter 24/64 - loss 1.72765382 - samples/sec: 106.70\n",
            "2020-02-03 17:37:44,515 epoch 28 - iter 30/64 - loss 1.59691374 - samples/sec: 120.85\n",
            "2020-02-03 17:37:48,628 epoch 28 - iter 36/64 - loss 1.56479071 - samples/sec: 74.06\n",
            "2020-02-03 17:37:51,487 epoch 28 - iter 42/64 - loss 1.54085761 - samples/sec: 115.59\n",
            "2020-02-03 17:37:54,421 epoch 28 - iter 48/64 - loss 1.48964745 - samples/sec: 110.92\n",
            "2020-02-03 17:37:57,713 epoch 28 - iter 54/64 - loss 1.50948025 - samples/sec: 96.38\n",
            "2020-02-03 17:38:00,764 epoch 28 - iter 60/64 - loss 1.47625434 - samples/sec: 104.64\n",
            "2020-02-03 17:38:03,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:38:03,177 EPOCH 28 done: loss 1.4689 - lr 0.1000\n",
            "2020-02-03 17:38:03,179 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:38:03,184 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:38:04,921 epoch 29 - iter 6/64 - loss 1.30607016 - samples/sec: 110.73\n",
            "2020-02-03 17:38:07,650 epoch 29 - iter 12/64 - loss 1.40792676 - samples/sec: 126.92\n",
            "2020-02-03 17:38:11,123 epoch 29 - iter 18/64 - loss 1.38712259 - samples/sec: 85.08\n",
            "2020-02-03 17:38:14,010 epoch 29 - iter 24/64 - loss 1.40048914 - samples/sec: 114.63\n",
            "2020-02-03 17:38:17,424 epoch 29 - iter 30/64 - loss 1.81778035 - samples/sec: 96.40\n",
            "2020-02-03 17:38:20,429 epoch 29 - iter 36/64 - loss 1.69028103 - samples/sec: 110.56\n",
            "2020-02-03 17:38:23,281 epoch 29 - iter 42/64 - loss 1.63938486 - samples/sec: 116.73\n",
            "2020-02-03 17:38:26,086 epoch 29 - iter 48/64 - loss 1.60787351 - samples/sec: 120.34\n",
            "2020-02-03 17:38:29,287 epoch 29 - iter 54/64 - loss 1.55589236 - samples/sec: 101.78\n",
            "2020-02-03 17:38:32,650 epoch 29 - iter 60/64 - loss 1.57999329 - samples/sec: 93.50\n",
            "2020-02-03 17:38:34,869 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:38:34,872 EPOCH 29 done: loss 1.5492 - lr 0.1000\n",
            "2020-02-03 17:38:34,874 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:38:34,878 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:38:36,573 epoch 30 - iter 6/64 - loss 3.48743625 - samples/sec: 113.53\n",
            "2020-02-03 17:38:39,649 epoch 30 - iter 12/64 - loss 2.41362350 - samples/sec: 108.27\n",
            "2020-02-03 17:38:42,557 epoch 30 - iter 18/64 - loss 2.06278212 - samples/sec: 112.45\n",
            "2020-02-03 17:38:45,736 epoch 30 - iter 24/64 - loss 1.90547342 - samples/sec: 97.92\n",
            "2020-02-03 17:38:49,021 epoch 30 - iter 30/64 - loss 1.75642975 - samples/sec: 102.49\n",
            "2020-02-03 17:38:52,194 epoch 30 - iter 36/64 - loss 1.66511832 - samples/sec: 97.60\n",
            "2020-02-03 17:38:55,008 epoch 30 - iter 42/64 - loss 1.60307211 - samples/sec: 112.10\n",
            "2020-02-03 17:38:58,418 epoch 30 - iter 48/64 - loss 1.53131665 - samples/sec: 91.10\n",
            "2020-02-03 17:39:01,870 epoch 30 - iter 54/64 - loss 1.49404853 - samples/sec: 89.55\n",
            "2020-02-03 17:39:05,119 epoch 30 - iter 60/64 - loss 1.46757176 - samples/sec: 103.33\n",
            "2020-02-03 17:39:07,775 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:39:07,777 EPOCH 30 done: loss 1.4592 - lr 0.1000\n",
            "2020-02-03 17:39:07,779 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:39:07,786 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:39:09,639 epoch 31 - iter 6/64 - loss 3.66611291 - samples/sec: 103.82\n",
            "2020-02-03 17:39:12,769 epoch 31 - iter 12/64 - loss 2.45439382 - samples/sec: 107.23\n",
            "2020-02-03 17:39:15,815 epoch 31 - iter 18/64 - loss 2.03301213 - samples/sec: 104.89\n",
            "2020-02-03 17:39:19,146 epoch 31 - iter 24/64 - loss 1.78334282 - samples/sec: 95.07\n",
            "2020-02-03 17:39:22,250 epoch 31 - iter 30/64 - loss 1.61448235 - samples/sec: 101.34\n",
            "2020-02-03 17:39:25,353 epoch 31 - iter 36/64 - loss 1.53116987 - samples/sec: 113.27\n",
            "2020-02-03 17:39:28,535 epoch 31 - iter 42/64 - loss 1.46258834 - samples/sec: 107.74\n",
            "2020-02-03 17:39:31,785 epoch 31 - iter 48/64 - loss 1.43776649 - samples/sec: 93.81\n",
            "2020-02-03 17:39:34,715 epoch 31 - iter 54/64 - loss 1.42217191 - samples/sec: 109.70\n",
            "2020-02-03 17:39:37,521 epoch 31 - iter 60/64 - loss 1.40302919 - samples/sec: 119.85\n",
            "2020-02-03 17:39:39,772 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:39:39,774 EPOCH 31 done: loss 1.3857 - lr 0.1000\n",
            "2020-02-03 17:39:39,777 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:39:39,782 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:39:41,331 epoch 32 - iter 6/64 - loss 1.17600274 - samples/sec: 124.23\n",
            "2020-02-03 17:39:44,105 epoch 32 - iter 12/64 - loss 1.18347001 - samples/sec: 122.58\n",
            "2020-02-03 17:39:47,402 epoch 32 - iter 18/64 - loss 1.20543755 - samples/sec: 96.74\n",
            "2020-02-03 17:39:49,982 epoch 32 - iter 24/64 - loss 1.16328307 - samples/sec: 140.56\n",
            "2020-02-03 17:39:53,446 epoch 32 - iter 30/64 - loss 1.19416439 - samples/sec: 88.60\n",
            "2020-02-03 17:39:56,463 epoch 32 - iter 36/64 - loss 1.17671670 - samples/sec: 105.34\n",
            "2020-02-03 17:39:59,846 epoch 32 - iter 42/64 - loss 1.17202808 - samples/sec: 93.91\n",
            "2020-02-03 17:40:02,880 epoch 32 - iter 48/64 - loss 1.22016087 - samples/sec: 109.95\n",
            "2020-02-03 17:40:06,512 epoch 32 - iter 54/64 - loss 1.21496295 - samples/sec: 79.31\n",
            "2020-02-03 17:40:09,492 epoch 32 - iter 60/64 - loss 1.40726600 - samples/sec: 104.22\n",
            "2020-02-03 17:40:12,054 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:40:12,056 EPOCH 32 done: loss 1.3780 - lr 0.1000\n",
            "2020-02-03 17:40:12,058 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:40:12,062 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:40:13,851 epoch 33 - iter 6/64 - loss 3.67810218 - samples/sec: 107.53\n",
            "2020-02-03 17:40:17,271 epoch 33 - iter 12/64 - loss 2.43579683 - samples/sec: 90.85\n",
            "2020-02-03 17:40:20,314 epoch 33 - iter 18/64 - loss 2.05792684 - samples/sec: 104.60\n",
            "2020-02-03 17:40:23,336 epoch 33 - iter 24/64 - loss 1.82435454 - samples/sec: 111.59\n",
            "2020-02-03 17:40:26,216 epoch 33 - iter 30/64 - loss 1.64526306 - samples/sec: 122.18\n",
            "2020-02-03 17:40:29,266 epoch 33 - iter 36/64 - loss 1.56692954 - samples/sec: 116.82\n",
            "2020-02-03 17:40:32,320 epoch 33 - iter 42/64 - loss 1.52453277 - samples/sec: 104.02\n",
            "2020-02-03 17:40:35,285 epoch 33 - iter 48/64 - loss 1.48542317 - samples/sec: 109.68\n",
            "2020-02-03 17:40:38,829 epoch 33 - iter 54/64 - loss 1.46804311 - samples/sec: 82.40\n",
            "2020-02-03 17:40:41,914 epoch 33 - iter 60/64 - loss 1.44872572 - samples/sec: 106.86\n",
            "2020-02-03 17:40:44,461 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:40:44,464 EPOCH 33 done: loss 1.4255 - lr 0.1000\n",
            "2020-02-03 17:40:44,469 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:40:44,479 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:40:46,986 epoch 34 - iter 6/64 - loss 4.09559175 - samples/sec: 76.76\n",
            "2020-02-03 17:40:50,398 epoch 34 - iter 12/64 - loss 2.57126864 - samples/sec: 103.56\n",
            "2020-02-03 17:40:54,083 epoch 34 - iter 18/64 - loss 2.09420016 - samples/sec: 88.53\n",
            "2020-02-03 17:40:56,981 epoch 34 - iter 24/64 - loss 1.81791509 - samples/sec: 113.99\n",
            "2020-02-03 17:41:00,027 epoch 34 - iter 30/64 - loss 1.66414856 - samples/sec: 104.56\n",
            "2020-02-03 17:41:02,820 epoch 34 - iter 36/64 - loss 1.57163725 - samples/sec: 114.07\n",
            "2020-02-03 17:41:05,673 epoch 34 - iter 42/64 - loss 1.47304849 - samples/sec: 123.19\n",
            "2020-02-03 17:41:08,928 epoch 34 - iter 48/64 - loss 1.41966614 - samples/sec: 94.00\n",
            "2020-02-03 17:41:12,077 epoch 34 - iter 54/64 - loss 1.38353646 - samples/sec: 110.83\n",
            "2020-02-03 17:41:15,288 epoch 34 - iter 60/64 - loss 1.40082525 - samples/sec: 100.64\n",
            "2020-02-03 17:41:17,574 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:41:17,577 EPOCH 34 done: loss 1.3874 - lr 0.1000\n",
            "2020-02-03 17:41:17,580 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:41:17,584 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:41:19,168 epoch 35 - iter 6/64 - loss 0.77084223 - samples/sec: 121.55\n",
            "2020-02-03 17:41:21,791 epoch 35 - iter 12/64 - loss 0.88411463 - samples/sec: 136.48\n",
            "2020-02-03 17:41:24,828 epoch 35 - iter 18/64 - loss 0.93460059 - samples/sec: 105.46\n",
            "2020-02-03 17:41:28,387 epoch 35 - iter 24/64 - loss 1.00277246 - samples/sec: 81.84\n",
            "2020-02-03 17:41:31,407 epoch 35 - iter 30/64 - loss 1.03467970 - samples/sec: 111.94\n",
            "2020-02-03 17:41:34,780 epoch 35 - iter 36/64 - loss 1.05654676 - samples/sec: 93.18\n",
            "2020-02-03 17:41:37,436 epoch 35 - iter 42/64 - loss 1.03472139 - samples/sec: 131.92\n",
            "2020-02-03 17:41:40,267 epoch 35 - iter 48/64 - loss 1.04476215 - samples/sec: 129.75\n",
            "2020-02-03 17:41:43,308 epoch 35 - iter 54/64 - loss 1.02186108 - samples/sec: 110.26\n",
            "2020-02-03 17:41:47,121 epoch 35 - iter 60/64 - loss 1.31738029 - samples/sec: 79.85\n",
            "2020-02-03 17:41:49,507 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:41:49,509 EPOCH 35 done: loss 1.2933 - lr 0.1000\n",
            "2020-02-03 17:41:49,510 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:41:49,518 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:41:51,422 epoch 36 - iter 6/64 - loss 1.13623641 - samples/sec: 101.08\n",
            "2020-02-03 17:41:55,355 epoch 36 - iter 12/64 - loss 1.03211163 - samples/sec: 79.52\n",
            "2020-02-03 17:41:58,755 epoch 36 - iter 18/64 - loss 1.87501354 - samples/sec: 95.88\n",
            "2020-02-03 17:42:01,921 epoch 36 - iter 24/64 - loss 1.74665914 - samples/sec: 108.82\n",
            "2020-02-03 17:42:04,892 epoch 36 - iter 30/64 - loss 1.61884797 - samples/sec: 115.14\n",
            "2020-02-03 17:42:07,840 epoch 36 - iter 36/64 - loss 1.54594643 - samples/sec: 104.38\n",
            "2020-02-03 17:42:10,719 epoch 36 - iter 42/64 - loss 1.47499518 - samples/sec: 114.99\n",
            "2020-02-03 17:42:13,955 epoch 36 - iter 48/64 - loss 1.41543301 - samples/sec: 99.06\n",
            "2020-02-03 17:42:17,152 epoch 36 - iter 54/64 - loss 1.40089862 - samples/sec: 101.41\n",
            "2020-02-03 17:42:20,022 epoch 36 - iter 60/64 - loss 1.35332459 - samples/sec: 116.04\n",
            "2020-02-03 17:42:22,282 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:42:22,287 EPOCH 36 done: loss 1.3341 - lr 0.1000\n",
            "2020-02-03 17:42:22,293 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:42:22,297 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:42:24,358 epoch 37 - iter 6/64 - loss 0.77310307 - samples/sec: 93.33\n",
            "2020-02-03 17:42:27,273 epoch 37 - iter 12/64 - loss 0.93010423 - samples/sec: 113.04\n",
            "2020-02-03 17:42:30,438 epoch 37 - iter 18/64 - loss 1.67142031 - samples/sec: 95.27\n",
            "2020-02-03 17:42:33,745 epoch 37 - iter 24/64 - loss 1.49982700 - samples/sec: 100.87\n",
            "2020-02-03 17:42:36,982 epoch 37 - iter 30/64 - loss 1.43145734 - samples/sec: 99.43\n",
            "2020-02-03 17:42:39,765 epoch 37 - iter 36/64 - loss 1.36404503 - samples/sec: 123.08\n",
            "2020-02-03 17:42:43,135 epoch 37 - iter 42/64 - loss 1.35510989 - samples/sec: 97.79\n",
            "2020-02-03 17:42:46,652 epoch 37 - iter 48/64 - loss 1.31073573 - samples/sec: 95.89\n",
            "2020-02-03 17:42:49,552 epoch 37 - iter 54/64 - loss 1.28615232 - samples/sec: 120.61\n",
            "2020-02-03 17:42:52,631 epoch 37 - iter 60/64 - loss 1.25516073 - samples/sec: 98.38\n",
            "2020-02-03 17:42:54,941 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:42:54,946 EPOCH 37 done: loss 1.2529 - lr 0.1000\n",
            "2020-02-03 17:42:54,947 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:42:54,952 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:42:56,594 epoch 38 - iter 6/64 - loss 0.83282922 - samples/sec: 117.13\n",
            "2020-02-03 17:42:59,508 epoch 38 - iter 12/64 - loss 1.05743184 - samples/sec: 106.44\n",
            "2020-02-03 17:43:02,899 epoch 38 - iter 18/64 - loss 1.09670533 - samples/sec: 87.59\n",
            "2020-02-03 17:43:05,790 epoch 38 - iter 24/64 - loss 1.04666214 - samples/sec: 114.72\n",
            "2020-02-03 17:43:08,706 epoch 38 - iter 30/64 - loss 1.00180016 - samples/sec: 119.88\n",
            "2020-02-03 17:43:12,075 epoch 38 - iter 36/64 - loss 1.29307389 - samples/sec: 89.11\n",
            "2020-02-03 17:43:15,310 epoch 38 - iter 42/64 - loss 1.24655986 - samples/sec: 99.44\n",
            "2020-02-03 17:43:18,489 epoch 38 - iter 48/64 - loss 1.24299561 - samples/sec: 103.14\n",
            "2020-02-03 17:43:21,245 epoch 38 - iter 54/64 - loss 1.19482191 - samples/sec: 126.33\n",
            "2020-02-03 17:43:24,440 epoch 38 - iter 60/64 - loss 1.17084673 - samples/sec: 101.06\n",
            "2020-02-03 17:43:26,642 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:43:26,644 EPOCH 38 done: loss 1.1467 - lr 0.1000\n",
            "2020-02-03 17:43:26,645 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:43:26,651 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:43:28,621 epoch 39 - iter 6/64 - loss 0.83134588 - samples/sec: 97.58\n",
            "2020-02-03 17:43:31,650 epoch 39 - iter 12/64 - loss 0.98344439 - samples/sec: 104.90\n",
            "2020-02-03 17:43:34,654 epoch 39 - iter 18/64 - loss 0.98693247 - samples/sec: 113.75\n",
            "2020-02-03 17:43:37,752 epoch 39 - iter 24/64 - loss 0.99109508 - samples/sec: 106.86\n",
            "2020-02-03 17:43:40,854 epoch 39 - iter 30/64 - loss 1.59283505 - samples/sec: 101.78\n",
            "2020-02-03 17:43:43,847 epoch 39 - iter 36/64 - loss 1.49597032 - samples/sec: 106.81\n",
            "2020-02-03 17:43:47,384 epoch 39 - iter 42/64 - loss 1.41623329 - samples/sec: 89.99\n",
            "2020-02-03 17:43:50,458 epoch 39 - iter 48/64 - loss 1.35524275 - samples/sec: 115.21\n",
            "2020-02-03 17:43:53,642 epoch 39 - iter 54/64 - loss 1.33001829 - samples/sec: 102.02\n",
            "2020-02-03 17:43:56,016 epoch 39 - iter 60/64 - loss 1.27816772 - samples/sec: 152.01\n",
            "2020-02-03 17:43:58,753 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:43:58,759 EPOCH 39 done: loss 1.2542 - lr 0.1000\n",
            "2020-02-03 17:43:58,763 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:43:58,770 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:44:00,984 epoch 40 - iter 6/64 - loss 1.00334594 - samples/sec: 86.92\n",
            "2020-02-03 17:44:04,081 epoch 40 - iter 12/64 - loss 1.86797437 - samples/sec: 92.13\n",
            "2020-02-03 17:44:07,097 epoch 40 - iter 18/64 - loss 1.56979204 - samples/sec: 106.32\n",
            "2020-02-03 17:44:09,808 epoch 40 - iter 24/64 - loss 1.39332840 - samples/sec: 127.49\n",
            "2020-02-03 17:44:12,733 epoch 40 - iter 30/64 - loss 1.36638749 - samples/sec: 118.70\n",
            "2020-02-03 17:44:15,956 epoch 40 - iter 36/64 - loss 1.28849138 - samples/sec: 95.39\n",
            "2020-02-03 17:44:19,105 epoch 40 - iter 42/64 - loss 1.24561756 - samples/sec: 102.44\n",
            "2020-02-03 17:44:21,826 epoch 40 - iter 48/64 - loss 1.18056639 - samples/sec: 125.95\n",
            "2020-02-03 17:44:24,806 epoch 40 - iter 54/64 - loss 1.16330126 - samples/sec: 114.75\n",
            "2020-02-03 17:44:27,825 epoch 40 - iter 60/64 - loss 1.13928058 - samples/sec: 106.62\n",
            "2020-02-03 17:44:30,143 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:44:30,145 EPOCH 40 done: loss 1.1162 - lr 0.1000\n",
            "2020-02-03 17:44:30,147 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:44:30,151 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:44:32,410 epoch 41 - iter 6/64 - loss 0.90863773 - samples/sec: 85.26\n",
            "2020-02-03 17:44:35,275 epoch 41 - iter 12/64 - loss 0.92769266 - samples/sec: 116.07\n",
            "2020-02-03 17:44:38,187 epoch 41 - iter 18/64 - loss 0.89167808 - samples/sec: 107.15\n",
            "2020-02-03 17:44:41,306 epoch 41 - iter 24/64 - loss 0.90181773 - samples/sec: 100.90\n",
            "2020-02-03 17:44:44,436 epoch 41 - iter 30/64 - loss 0.89346852 - samples/sec: 104.84\n",
            "2020-02-03 17:44:47,672 epoch 41 - iter 36/64 - loss 0.92978381 - samples/sec: 100.98\n",
            "2020-02-03 17:44:50,378 epoch 41 - iter 42/64 - loss 0.89983059 - samples/sec: 137.13\n",
            "2020-02-03 17:44:53,428 epoch 41 - iter 48/64 - loss 0.89539249 - samples/sec: 99.31\n",
            "2020-02-03 17:44:56,281 epoch 41 - iter 54/64 - loss 0.92470509 - samples/sec: 119.89\n",
            "2020-02-03 17:44:59,623 epoch 41 - iter 60/64 - loss 0.91551073 - samples/sec: 94.13\n",
            "2020-02-03 17:45:02,254 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:45:02,256 EPOCH 41 done: loss 1.0022 - lr 0.1000\n",
            "2020-02-03 17:45:02,258 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:45:02,265 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:45:04,336 epoch 42 - iter 6/64 - loss 1.07030171 - samples/sec: 92.85\n",
            "2020-02-03 17:45:07,574 epoch 42 - iter 12/64 - loss 0.95856332 - samples/sec: 94.63\n",
            "2020-02-03 17:45:11,142 epoch 42 - iter 18/64 - loss 1.65811071 - samples/sec: 88.83\n",
            "2020-02-03 17:45:13,812 epoch 42 - iter 24/64 - loss 1.44875068 - samples/sec: 131.57\n",
            "2020-02-03 17:45:17,250 epoch 42 - iter 30/64 - loss 1.31078142 - samples/sec: 90.27\n",
            "2020-02-03 17:45:20,270 epoch 42 - iter 36/64 - loss 1.23188733 - samples/sec: 112.40\n",
            "2020-02-03 17:45:23,415 epoch 42 - iter 42/64 - loss 1.16917825 - samples/sec: 104.24\n",
            "2020-02-03 17:45:26,733 epoch 42 - iter 48/64 - loss 1.14239223 - samples/sec: 95.15\n",
            "2020-02-03 17:45:29,897 epoch 42 - iter 54/64 - loss 1.10401965 - samples/sec: 109.97\n",
            "2020-02-03 17:45:32,999 epoch 42 - iter 60/64 - loss 1.09164093 - samples/sec: 101.68\n",
            "2020-02-03 17:45:35,372 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:45:35,374 EPOCH 42 done: loss 1.0813 - lr 0.1000\n",
            "2020-02-03 17:45:35,375 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:45:35,379 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:45:36,907 epoch 43 - iter 6/64 - loss 0.72925193 - samples/sec: 126.15\n",
            "2020-02-03 17:45:40,025 epoch 43 - iter 12/64 - loss 2.12409672 - samples/sec: 100.76\n",
            "2020-02-03 17:45:43,116 epoch 43 - iter 18/64 - loss 1.72414641 - samples/sec: 102.27\n",
            "2020-02-03 17:45:46,782 epoch 43 - iter 24/64 - loss 1.49616397 - samples/sec: 90.47\n",
            "2020-02-03 17:45:49,801 epoch 43 - iter 30/64 - loss 1.37945510 - samples/sec: 112.73\n",
            "2020-02-03 17:45:53,056 epoch 43 - iter 36/64 - loss 1.32229046 - samples/sec: 93.67\n",
            "2020-02-03 17:45:56,131 epoch 43 - iter 42/64 - loss 1.24205869 - samples/sec: 110.37\n",
            "2020-02-03 17:45:59,352 epoch 43 - iter 48/64 - loss 1.21594431 - samples/sec: 107.14\n",
            "2020-02-03 17:46:02,608 epoch 43 - iter 54/64 - loss 1.18698920 - samples/sec: 108.81\n",
            "2020-02-03 17:46:06,260 epoch 43 - iter 60/64 - loss 1.16983841 - samples/sec: 82.12\n",
            "2020-02-03 17:46:08,494 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:46:08,499 EPOCH 43 done: loss 1.1486 - lr 0.1000\n",
            "2020-02-03 17:46:08,502 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:46:08,510 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:46:10,176 epoch 44 - iter 6/64 - loss 0.99370569 - samples/sec: 115.60\n",
            "2020-02-03 17:46:13,083 epoch 44 - iter 12/64 - loss 0.80577209 - samples/sec: 113.79\n",
            "2020-02-03 17:46:15,931 epoch 44 - iter 18/64 - loss 0.78761695 - samples/sec: 109.98\n",
            "2020-02-03 17:46:19,337 epoch 44 - iter 24/64 - loss 0.86054952 - samples/sec: 88.24\n",
            "2020-02-03 17:46:22,549 epoch 44 - iter 30/64 - loss 0.90545054 - samples/sec: 100.76\n",
            "2020-02-03 17:46:25,488 epoch 44 - iter 36/64 - loss 0.88595520 - samples/sec: 111.12\n",
            "2020-02-03 17:46:28,367 epoch 44 - iter 42/64 - loss 0.90261435 - samples/sec: 114.61\n",
            "2020-02-03 17:46:31,109 epoch 44 - iter 48/64 - loss 0.87537254 - samples/sec: 133.33\n",
            "2020-02-03 17:46:34,101 epoch 44 - iter 54/64 - loss 0.88324871 - samples/sec: 110.10\n",
            "2020-02-03 17:46:37,224 epoch 44 - iter 60/64 - loss 1.15445572 - samples/sec: 101.73\n",
            "2020-02-03 17:46:39,332 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:46:39,334 EPOCH 44 done: loss 1.1182 - lr 0.1000\n",
            "2020-02-03 17:46:39,338 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 17:46:39,346 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:46:40,932 epoch 45 - iter 6/64 - loss 0.80575558 - samples/sec: 121.31\n",
            "2020-02-03 17:46:43,827 epoch 45 - iter 12/64 - loss 0.75263515 - samples/sec: 113.59\n",
            "2020-02-03 17:46:47,038 epoch 45 - iter 18/64 - loss 0.81198441 - samples/sec: 99.70\n",
            "2020-02-03 17:46:50,150 epoch 45 - iter 24/64 - loss 0.84533486 - samples/sec: 100.84\n",
            "2020-02-03 17:46:53,889 epoch 45 - iter 30/64 - loss 0.83653658 - samples/sec: 75.52\n",
            "2020-02-03 17:46:56,812 epoch 45 - iter 36/64 - loss 0.80107793 - samples/sec: 117.82\n",
            "2020-02-03 17:46:59,841 epoch 45 - iter 42/64 - loss 1.27188519 - samples/sec: 106.38\n",
            "2020-02-03 17:47:02,862 epoch 45 - iter 48/64 - loss 1.22995817 - samples/sec: 106.04\n",
            "2020-02-03 17:47:05,716 epoch 45 - iter 54/64 - loss 1.20189810 - samples/sec: 124.71\n",
            "2020-02-03 17:47:08,595 epoch 45 - iter 60/64 - loss 1.14650669 - samples/sec: 121.78\n",
            "2020-02-03 17:47:11,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:47:11,213 EPOCH 45 done: loss 1.1388 - lr 0.1000\n",
            "Epoch    35: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-02-03 17:47:11,215 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 17:47:11,220 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:47:12,851 epoch 46 - iter 6/64 - loss 0.66468791 - samples/sec: 118.16\n",
            "2020-02-03 17:47:15,924 epoch 46 - iter 12/64 - loss 0.76233281 - samples/sec: 103.35\n",
            "2020-02-03 17:47:19,211 epoch 46 - iter 18/64 - loss 1.60197225 - samples/sec: 97.53\n",
            "2020-02-03 17:47:22,304 epoch 46 - iter 24/64 - loss 1.42668698 - samples/sec: 99.66\n",
            "2020-02-03 17:47:25,090 epoch 46 - iter 30/64 - loss 1.29837270 - samples/sec: 130.73\n",
            "2020-02-03 17:47:28,039 epoch 46 - iter 36/64 - loss 1.19905909 - samples/sec: 116.24\n",
            "2020-02-03 17:47:30,954 epoch 46 - iter 42/64 - loss 1.12329228 - samples/sec: 118.66\n",
            "2020-02-03 17:47:34,261 epoch 46 - iter 48/64 - loss 1.07832796 - samples/sec: 91.66\n",
            "2020-02-03 17:47:37,540 epoch 46 - iter 54/64 - loss 1.05356125 - samples/sec: 102.32\n",
            "2020-02-03 17:47:40,767 epoch 46 - iter 60/64 - loss 1.03236135 - samples/sec: 100.21\n",
            "2020-02-03 17:47:43,515 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:47:43,519 EPOCH 46 done: loss 1.0237 - lr 0.0500\n",
            "2020-02-03 17:47:43,523 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:47:43,529 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:47:46,115 epoch 47 - iter 6/64 - loss 0.87740352 - samples/sec: 74.38\n",
            "2020-02-03 17:47:49,391 epoch 47 - iter 12/64 - loss 2.28908114 - samples/sec: 102.63\n",
            "2020-02-03 17:47:52,423 epoch 47 - iter 18/64 - loss 1.81009949 - samples/sec: 99.10\n",
            "2020-02-03 17:47:55,592 epoch 47 - iter 24/64 - loss 1.50122201 - samples/sec: 108.93\n",
            "2020-02-03 17:47:58,715 epoch 47 - iter 30/64 - loss 1.35770450 - samples/sec: 95.54\n",
            "2020-02-03 17:48:01,597 epoch 47 - iter 36/64 - loss 1.24973077 - samples/sec: 115.18\n",
            "2020-02-03 17:48:04,535 epoch 47 - iter 42/64 - loss 1.17489288 - samples/sec: 110.94\n",
            "2020-02-03 17:48:07,629 epoch 47 - iter 48/64 - loss 1.12744654 - samples/sec: 101.88\n",
            "2020-02-03 17:48:10,515 epoch 47 - iter 54/64 - loss 1.06978198 - samples/sec: 123.99\n",
            "2020-02-03 17:48:13,648 epoch 47 - iter 60/64 - loss 1.05272801 - samples/sec: 104.56\n",
            "2020-02-03 17:48:16,173 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:48:16,175 EPOCH 47 done: loss 1.0332 - lr 0.0500\n",
            "2020-02-03 17:48:16,176 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:48:16,181 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:48:17,744 epoch 48 - iter 6/64 - loss 0.73263702 - samples/sec: 123.13\n",
            "2020-02-03 17:48:21,030 epoch 48 - iter 12/64 - loss 1.20401157 - samples/sec: 96.36\n",
            "2020-02-03 17:48:24,203 epoch 48 - iter 18/64 - loss 1.10025451 - samples/sec: 97.63\n",
            "2020-02-03 17:48:27,319 epoch 48 - iter 24/64 - loss 0.96516247 - samples/sec: 106.47\n",
            "2020-02-03 17:48:30,213 epoch 48 - iter 30/64 - loss 0.88881401 - samples/sec: 115.05\n",
            "2020-02-03 17:48:32,914 epoch 48 - iter 36/64 - loss 0.85854626 - samples/sec: 128.00\n",
            "2020-02-03 17:48:36,708 epoch 48 - iter 42/64 - loss 0.83950997 - samples/sec: 77.35\n",
            "2020-02-03 17:48:39,591 epoch 48 - iter 48/64 - loss 0.81221800 - samples/sec: 121.14\n",
            "2020-02-03 17:48:42,833 epoch 48 - iter 54/64 - loss 0.79305975 - samples/sec: 104.77\n",
            "2020-02-03 17:48:46,321 epoch 48 - iter 60/64 - loss 0.78141222 - samples/sec: 87.94\n",
            "2020-02-03 17:48:48,776 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:48:48,778 EPOCH 48 done: loss 0.7871 - lr 0.0500\n",
            "2020-02-03 17:48:48,780 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:48:48,787 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:48:50,671 epoch 49 - iter 6/64 - loss 0.62553212 - samples/sec: 102.13\n",
            "2020-02-03 17:48:54,032 epoch 49 - iter 12/64 - loss 0.64923048 - samples/sec: 104.71\n",
            "2020-02-03 17:48:56,970 epoch 49 - iter 18/64 - loss 0.67425646 - samples/sec: 118.49\n",
            "2020-02-03 17:49:00,069 epoch 49 - iter 24/64 - loss 0.65782075 - samples/sec: 103.94\n",
            "2020-02-03 17:49:03,080 epoch 49 - iter 30/64 - loss 0.66681546 - samples/sec: 106.74\n",
            "2020-02-03 17:49:05,863 epoch 49 - iter 36/64 - loss 0.66097986 - samples/sec: 121.83\n",
            "2020-02-03 17:49:09,456 epoch 49 - iter 42/64 - loss 0.66065145 - samples/sec: 83.90\n",
            "2020-02-03 17:49:12,468 epoch 49 - iter 48/64 - loss 1.00029112 - samples/sec: 106.30\n",
            "2020-02-03 17:49:15,610 epoch 49 - iter 54/64 - loss 0.96959444 - samples/sec: 99.07\n",
            "2020-02-03 17:49:18,809 epoch 49 - iter 60/64 - loss 0.93016024 - samples/sec: 102.80\n",
            "2020-02-03 17:49:21,335 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:49:21,341 EPOCH 49 done: loss 0.9168 - lr 0.0500\n",
            "2020-02-03 17:49:21,346 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:49:21,352 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:49:23,378 epoch 50 - iter 6/64 - loss 3.17792203 - samples/sec: 94.94\n",
            "2020-02-03 17:49:26,455 epoch 50 - iter 12/64 - loss 1.97149657 - samples/sec: 108.29\n",
            "2020-02-03 17:49:29,504 epoch 50 - iter 18/64 - loss 1.45843650 - samples/sec: 117.66\n",
            "2020-02-03 17:49:32,691 epoch 50 - iter 24/64 - loss 1.29132612 - samples/sec: 96.90\n",
            "2020-02-03 17:49:36,000 epoch 50 - iter 30/64 - loss 1.12838081 - samples/sec: 92.21\n",
            "2020-02-03 17:49:39,177 epoch 50 - iter 36/64 - loss 1.07422857 - samples/sec: 97.72\n",
            "2020-02-03 17:49:41,982 epoch 50 - iter 42/64 - loss 0.98914521 - samples/sec: 127.83\n",
            "2020-02-03 17:49:45,102 epoch 50 - iter 48/64 - loss 0.94705809 - samples/sec: 106.07\n",
            "2020-02-03 17:49:48,398 epoch 50 - iter 54/64 - loss 0.91281356 - samples/sec: 102.11\n",
            "2020-02-03 17:49:52,233 epoch 50 - iter 60/64 - loss 0.90684924 - samples/sec: 91.71\n",
            "2020-02-03 17:49:54,847 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:49:54,850 EPOCH 50 done: loss 0.9108 - lr 0.0500\n",
            "2020-02-03 17:49:54,852 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:49:54,859 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:49:56,676 epoch 51 - iter 6/64 - loss 0.60069526 - samples/sec: 105.83\n",
            "2020-02-03 17:50:00,164 epoch 51 - iter 12/64 - loss 0.66559018 - samples/sec: 92.30\n",
            "2020-02-03 17:50:03,625 epoch 51 - iter 18/64 - loss 0.63508871 - samples/sec: 93.17\n",
            "2020-02-03 17:50:06,592 epoch 51 - iter 24/64 - loss 0.60058357 - samples/sec: 109.08\n",
            "2020-02-03 17:50:09,622 epoch 51 - iter 30/64 - loss 0.62737620 - samples/sec: 111.35\n",
            "2020-02-03 17:50:12,768 epoch 51 - iter 36/64 - loss 0.64467233 - samples/sec: 98.60\n",
            "2020-02-03 17:50:16,055 epoch 51 - iter 42/64 - loss 0.65643183 - samples/sec: 97.25\n",
            "2020-02-03 17:50:19,146 epoch 51 - iter 48/64 - loss 0.65252064 - samples/sec: 102.31\n",
            "2020-02-03 17:50:22,648 epoch 51 - iter 54/64 - loss 0.86885407 - samples/sec: 87.72\n",
            "2020-02-03 17:50:25,597 epoch 51 - iter 60/64 - loss 0.85254387 - samples/sec: 111.43\n",
            "2020-02-03 17:50:27,926 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:50:27,929 EPOCH 51 done: loss 0.8465 - lr 0.0500\n",
            "2020-02-03 17:50:27,931 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 17:50:27,937 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:50:29,515 epoch 52 - iter 6/64 - loss 0.62934579 - samples/sec: 121.94\n",
            "2020-02-03 17:50:33,039 epoch 52 - iter 12/64 - loss 0.67665986 - samples/sec: 86.59\n",
            "2020-02-03 17:50:36,281 epoch 52 - iter 18/64 - loss 0.63496864 - samples/sec: 94.14\n",
            "2020-02-03 17:50:39,177 epoch 52 - iter 24/64 - loss 0.65087681 - samples/sec: 120.06\n",
            "2020-02-03 17:50:42,585 epoch 52 - iter 30/64 - loss 0.64672921 - samples/sec: 98.21\n",
            "2020-02-03 17:50:46,149 epoch 52 - iter 36/64 - loss 0.65023461 - samples/sec: 81.70\n",
            "2020-02-03 17:50:49,598 epoch 52 - iter 42/64 - loss 0.83883746 - samples/sec: 90.36\n",
            "2020-02-03 17:50:52,786 epoch 52 - iter 48/64 - loss 0.83970368 - samples/sec: 102.23\n",
            "2020-02-03 17:50:55,872 epoch 52 - iter 54/64 - loss 0.80326797 - samples/sec: 107.51\n",
            "2020-02-03 17:50:58,989 epoch 52 - iter 60/64 - loss 0.79720482 - samples/sec: 100.93\n",
            "2020-02-03 17:51:01,413 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:51:01,417 EPOCH 52 done: loss 0.7848 - lr 0.0500\n",
            "2020-02-03 17:51:01,421 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:51:01,426 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:51:03,280 epoch 53 - iter 6/64 - loss 0.79491995 - samples/sec: 103.71\n",
            "2020-02-03 17:51:06,751 epoch 53 - iter 12/64 - loss 0.63706217 - samples/sec: 93.20\n",
            "2020-02-03 17:51:10,386 epoch 53 - iter 18/64 - loss 0.64052719 - samples/sec: 90.35\n",
            "2020-02-03 17:51:13,665 epoch 53 - iter 24/64 - loss 0.64587506 - samples/sec: 108.93\n",
            "2020-02-03 17:51:17,327 epoch 53 - iter 30/64 - loss 0.98654400 - samples/sec: 85.66\n",
            "2020-02-03 17:51:20,470 epoch 53 - iter 36/64 - loss 0.92144917 - samples/sec: 104.20\n",
            "2020-02-03 17:51:23,653 epoch 53 - iter 42/64 - loss 0.87585209 - samples/sec: 102.53\n",
            "2020-02-03 17:51:26,804 epoch 53 - iter 48/64 - loss 0.83430554 - samples/sec: 104.99\n",
            "2020-02-03 17:51:29,871 epoch 53 - iter 54/64 - loss 0.81313747 - samples/sec: 109.11\n",
            "2020-02-03 17:51:33,033 epoch 53 - iter 60/64 - loss 0.80148779 - samples/sec: 103.98\n",
            "2020-02-03 17:51:35,484 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:51:35,487 EPOCH 53 done: loss 0.7886 - lr 0.0500\n",
            "2020-02-03 17:51:35,489 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:51:35,493 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:51:37,537 epoch 54 - iter 6/64 - loss 1.19102908 - samples/sec: 94.36\n",
            "2020-02-03 17:51:40,707 epoch 54 - iter 12/64 - loss 0.89910418 - samples/sec: 102.50\n",
            "2020-02-03 17:51:43,868 epoch 54 - iter 18/64 - loss 0.81286779 - samples/sec: 109.25\n",
            "2020-02-03 17:51:47,368 epoch 54 - iter 24/64 - loss 0.75894713 - samples/sec: 96.23\n",
            "2020-02-03 17:51:50,508 epoch 54 - iter 30/64 - loss 0.72301145 - samples/sec: 104.15\n",
            "2020-02-03 17:51:53,547 epoch 54 - iter 36/64 - loss 0.70159417 - samples/sec: 104.98\n",
            "2020-02-03 17:51:56,626 epoch 54 - iter 42/64 - loss 0.68716784 - samples/sec: 108.60\n",
            "2020-02-03 17:51:59,953 epoch 54 - iter 48/64 - loss 0.68209993 - samples/sec: 99.49\n",
            "2020-02-03 17:52:03,162 epoch 54 - iter 54/64 - loss 0.66324199 - samples/sec: 100.61\n",
            "2020-02-03 17:52:06,637 epoch 54 - iter 60/64 - loss 0.65091133 - samples/sec: 85.03\n",
            "2020-02-03 17:52:09,088 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:52:09,092 EPOCH 54 done: loss 0.6514 - lr 0.0500\n",
            "2020-02-03 17:52:09,094 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:52:09,099 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:52:10,755 epoch 55 - iter 6/64 - loss 0.47727553 - samples/sec: 116.18\n",
            "2020-02-03 17:52:13,704 epoch 55 - iter 12/64 - loss 0.51935393 - samples/sec: 117.05\n",
            "2020-02-03 17:52:16,933 epoch 55 - iter 18/64 - loss 0.54153198 - samples/sec: 100.82\n",
            "2020-02-03 17:52:20,216 epoch 55 - iter 24/64 - loss 0.58043036 - samples/sec: 92.50\n",
            "2020-02-03 17:52:23,920 epoch 55 - iter 30/64 - loss 0.60097632 - samples/sec: 81.14\n",
            "2020-02-03 17:52:26,837 epoch 55 - iter 36/64 - loss 0.59144567 - samples/sec: 119.00\n",
            "2020-02-03 17:52:30,113 epoch 55 - iter 42/64 - loss 0.60140447 - samples/sec: 108.91\n",
            "2020-02-03 17:52:33,427 epoch 55 - iter 48/64 - loss 0.60587413 - samples/sec: 100.34\n",
            "2020-02-03 17:52:36,562 epoch 55 - iter 54/64 - loss 0.81132493 - samples/sec: 99.19\n",
            "2020-02-03 17:52:39,283 epoch 55 - iter 60/64 - loss 0.79476192 - samples/sec: 127.17\n",
            "2020-02-03 17:52:42,449 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:52:42,450 EPOCH 55 done: loss 0.7967 - lr 0.0500\n",
            "2020-02-03 17:52:42,452 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:52:42,458 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:52:44,666 epoch 56 - iter 6/64 - loss 0.41568048 - samples/sec: 87.18\n",
            "2020-02-03 17:52:48,101 epoch 56 - iter 12/64 - loss 0.45135128 - samples/sec: 94.95\n",
            "2020-02-03 17:52:51,108 epoch 56 - iter 18/64 - loss 0.56079988 - samples/sec: 112.42\n",
            "2020-02-03 17:52:54,146 epoch 56 - iter 24/64 - loss 0.56844360 - samples/sec: 118.10\n",
            "2020-02-03 17:52:57,550 epoch 56 - iter 30/64 - loss 0.63469860 - samples/sec: 92.41\n",
            "2020-02-03 17:53:00,687 epoch 56 - iter 36/64 - loss 0.63592622 - samples/sec: 110.69\n",
            "2020-02-03 17:53:04,162 epoch 56 - iter 42/64 - loss 0.60916902 - samples/sec: 92.94\n",
            "2020-02-03 17:53:07,207 epoch 56 - iter 48/64 - loss 0.61798944 - samples/sec: 110.96\n",
            "2020-02-03 17:53:10,812 epoch 56 - iter 54/64 - loss 0.87305453 - samples/sec: 87.43\n",
            "2020-02-03 17:53:13,838 epoch 56 - iter 60/64 - loss 0.86381015 - samples/sec: 118.50\n",
            "2020-02-03 17:53:16,307 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:53:16,308 EPOCH 56 done: loss 0.8497 - lr 0.0500\n",
            "2020-02-03 17:53:16,310 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:53:16,317 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:53:18,433 epoch 57 - iter 6/64 - loss 0.42162640 - samples/sec: 90.85\n",
            "2020-02-03 17:53:21,505 epoch 57 - iter 12/64 - loss 0.43122583 - samples/sec: 114.56\n",
            "2020-02-03 17:53:24,917 epoch 57 - iter 18/64 - loss 0.47578663 - samples/sec: 100.87\n",
            "2020-02-03 17:53:27,824 epoch 57 - iter 24/64 - loss 0.51727840 - samples/sec: 119.79\n",
            "2020-02-03 17:53:31,277 epoch 57 - iter 30/64 - loss 0.54343244 - samples/sec: 99.19\n",
            "2020-02-03 17:53:34,287 epoch 57 - iter 36/64 - loss 0.57853738 - samples/sec: 107.01\n",
            "2020-02-03 17:53:37,995 epoch 57 - iter 42/64 - loss 0.58640865 - samples/sec: 83.59\n",
            "2020-02-03 17:53:41,352 epoch 57 - iter 48/64 - loss 0.61482414 - samples/sec: 93.83\n",
            "2020-02-03 17:53:44,481 epoch 57 - iter 54/64 - loss 0.59883077 - samples/sec: 106.46\n",
            "2020-02-03 17:53:48,174 epoch 57 - iter 60/64 - loss 0.91844768 - samples/sec: 88.31\n",
            "2020-02-03 17:53:50,680 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:53:50,682 EPOCH 57 done: loss 0.8946 - lr 0.0500\n",
            "2020-02-03 17:53:50,686 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 17:53:50,695 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:53:53,046 epoch 58 - iter 6/64 - loss 0.43006773 - samples/sec: 81.82\n",
            "2020-02-03 17:53:56,313 epoch 58 - iter 12/64 - loss 0.55931278 - samples/sec: 109.10\n",
            "2020-02-03 17:53:59,663 epoch 58 - iter 18/64 - loss 0.59613092 - samples/sec: 94.27\n",
            "2020-02-03 17:54:02,932 epoch 58 - iter 24/64 - loss 0.59031331 - samples/sec: 93.99\n",
            "2020-02-03 17:54:06,160 epoch 58 - iter 30/64 - loss 0.90112740 - samples/sec: 100.35\n",
            "2020-02-03 17:54:09,157 epoch 58 - iter 36/64 - loss 0.82070823 - samples/sec: 115.97\n",
            "2020-02-03 17:54:12,342 epoch 58 - iter 42/64 - loss 0.75384867 - samples/sec: 102.12\n",
            "2020-02-03 17:54:15,731 epoch 58 - iter 48/64 - loss 0.73814867 - samples/sec: 92.12\n",
            "2020-02-03 17:54:18,881 epoch 58 - iter 54/64 - loss 0.70537527 - samples/sec: 110.65\n",
            "2020-02-03 17:54:21,979 epoch 58 - iter 60/64 - loss 0.70536667 - samples/sec: 106.84\n",
            "2020-02-03 17:54:24,514 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:54:24,516 EPOCH 58 done: loss 0.6977 - lr 0.0500\n",
            "Epoch    48: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-02-03 17:54:24,519 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 17:54:24,524 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:54:26,131 epoch 59 - iter 6/64 - loss 0.43401051 - samples/sec: 119.72\n",
            "2020-02-03 17:54:29,536 epoch 59 - iter 12/64 - loss 0.48151997 - samples/sec: 91.79\n",
            "2020-02-03 17:54:32,383 epoch 59 - iter 18/64 - loss 0.47601403 - samples/sec: 124.61\n",
            "2020-02-03 17:54:35,390 epoch 59 - iter 24/64 - loss 0.47324128 - samples/sec: 107.25\n",
            "2020-02-03 17:54:38,090 epoch 59 - iter 30/64 - loss 0.49711732 - samples/sec: 113.83\n",
            "2020-02-03 17:54:40,810 epoch 59 - iter 36/64 - loss 0.49446031 - samples/sec: 126.20\n",
            "2020-02-03 17:54:44,253 epoch 59 - iter 42/64 - loss 0.88846333 - samples/sec: 90.45\n",
            "2020-02-03 17:54:47,776 epoch 59 - iter 48/64 - loss 0.86758984 - samples/sec: 91.11\n",
            "2020-02-03 17:54:50,822 epoch 59 - iter 54/64 - loss 0.83133683 - samples/sec: 104.32\n",
            "2020-02-03 17:54:54,384 epoch 59 - iter 60/64 - loss 0.80215827 - samples/sec: 89.47\n",
            "2020-02-03 17:54:56,906 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:54:56,909 EPOCH 59 done: loss 0.7860 - lr 0.0250\n",
            "2020-02-03 17:54:56,913 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:54:56,923 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:54:58,688 epoch 60 - iter 6/64 - loss 0.51777188 - samples/sec: 109.14\n",
            "2020-02-03 17:55:01,969 epoch 60 - iter 12/64 - loss 0.51483831 - samples/sec: 102.07\n",
            "2020-02-03 17:55:05,328 epoch 60 - iter 18/64 - loss 0.58040647 - samples/sec: 98.56\n",
            "2020-02-03 17:55:08,860 epoch 60 - iter 24/64 - loss 0.57384796 - samples/sec: 90.14\n",
            "2020-02-03 17:55:12,136 epoch 60 - iter 30/64 - loss 0.57090221 - samples/sec: 92.54\n",
            "2020-02-03 17:55:15,391 epoch 60 - iter 36/64 - loss 0.55973658 - samples/sec: 98.87\n",
            "2020-02-03 17:55:18,569 epoch 60 - iter 42/64 - loss 0.62675483 - samples/sec: 103.59\n",
            "2020-02-03 17:55:21,392 epoch 60 - iter 48/64 - loss 0.59693024 - samples/sec: 136.53\n",
            "2020-02-03 17:55:24,459 epoch 60 - iter 54/64 - loss 0.60364868 - samples/sec: 109.04\n",
            "2020-02-03 17:55:27,955 epoch 60 - iter 60/64 - loss 0.60398179 - samples/sec: 92.21\n",
            "2020-02-03 17:55:30,516 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:55:30,521 EPOCH 60 done: loss 0.5964 - lr 0.0250\n",
            "2020-02-03 17:55:30,523 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 17:55:30,529 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:55:32,350 epoch 61 - iter 6/64 - loss 0.62958567 - samples/sec: 105.67\n",
            "2020-02-03 17:55:35,245 epoch 61 - iter 12/64 - loss 0.58119742 - samples/sec: 121.02\n",
            "2020-02-03 17:55:38,241 epoch 61 - iter 18/64 - loss 0.58092999 - samples/sec: 112.88\n",
            "2020-02-03 17:55:41,563 epoch 61 - iter 24/64 - loss 0.53197734 - samples/sec: 99.82\n",
            "2020-02-03 17:55:45,440 epoch 61 - iter 30/64 - loss 0.53869741 - samples/sec: 74.62\n",
            "2020-02-03 17:55:48,738 epoch 61 - iter 36/64 - loss 0.51760417 - samples/sec: 113.58\n",
            "2020-02-03 17:55:52,351 epoch 61 - iter 42/64 - loss 0.84391441 - samples/sec: 93.32\n",
            "2020-02-03 17:55:55,526 epoch 61 - iter 48/64 - loss 0.79122003 - samples/sec: 109.13\n",
            "2020-02-03 17:55:58,865 epoch 61 - iter 54/64 - loss 0.76489015 - samples/sec: 95.46\n",
            "2020-02-03 17:56:02,183 epoch 61 - iter 60/64 - loss 0.74463181 - samples/sec: 101.64\n",
            "2020-02-03 17:56:05,008 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:56:05,013 EPOCH 61 done: loss 0.7210 - lr 0.0250\n",
            "2020-02-03 17:56:05,015 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:56:05,021 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:56:06,557 epoch 62 - iter 6/64 - loss 0.45833760 - samples/sec: 125.93\n",
            "2020-02-03 17:56:10,312 epoch 62 - iter 12/64 - loss 0.59532819 - samples/sec: 89.36\n",
            "2020-02-03 17:56:13,476 epoch 62 - iter 18/64 - loss 0.53275156 - samples/sec: 104.29\n",
            "2020-02-03 17:56:17,241 epoch 62 - iter 24/64 - loss 0.83221053 - samples/sec: 77.98\n",
            "2020-02-03 17:56:20,459 epoch 62 - iter 30/64 - loss 0.78763207 - samples/sec: 119.92\n",
            "2020-02-03 17:56:23,817 epoch 62 - iter 36/64 - loss 0.74177775 - samples/sec: 110.62\n",
            "2020-02-03 17:56:27,083 epoch 62 - iter 42/64 - loss 0.70985598 - samples/sec: 98.23\n",
            "2020-02-03 17:56:30,476 epoch 62 - iter 48/64 - loss 0.68264194 - samples/sec: 96.76\n",
            "2020-02-03 17:56:33,515 epoch 62 - iter 54/64 - loss 0.67589237 - samples/sec: 104.90\n",
            "2020-02-03 17:56:37,202 epoch 62 - iter 60/64 - loss 0.66683681 - samples/sec: 81.12\n",
            "2020-02-03 17:56:39,321 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:56:39,323 EPOCH 62 done: loss 0.6453 - lr 0.0250\n",
            "2020-02-03 17:56:39,328 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:56:39,333 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:56:41,245 epoch 63 - iter 6/64 - loss 0.52563268 - samples/sec: 100.62\n",
            "2020-02-03 17:56:44,844 epoch 63 - iter 12/64 - loss 0.46317462 - samples/sec: 85.43\n",
            "2020-02-03 17:56:48,095 epoch 63 - iter 18/64 - loss 0.46360253 - samples/sec: 104.88\n",
            "2020-02-03 17:56:51,059 epoch 63 - iter 24/64 - loss 0.45244880 - samples/sec: 109.59\n",
            "2020-02-03 17:56:54,804 epoch 63 - iter 30/64 - loss 0.46123938 - samples/sec: 90.37\n",
            "2020-02-03 17:56:58,082 epoch 63 - iter 36/64 - loss 0.45409105 - samples/sec: 107.88\n",
            "2020-02-03 17:57:01,018 epoch 63 - iter 42/64 - loss 0.46760399 - samples/sec: 111.76\n",
            "2020-02-03 17:57:03,977 epoch 63 - iter 48/64 - loss 0.48862487 - samples/sec: 110.12\n",
            "2020-02-03 17:57:07,357 epoch 63 - iter 54/64 - loss 0.64008040 - samples/sec: 92.86\n",
            "2020-02-03 17:57:10,337 epoch 63 - iter 60/64 - loss 0.63053983 - samples/sec: 114.83\n",
            "2020-02-03 17:57:13,271 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:57:13,274 EPOCH 63 done: loss 0.6358 - lr 0.0250\n",
            "2020-02-03 17:57:13,280 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 17:57:13,285 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:57:15,494 epoch 64 - iter 6/64 - loss 0.49441710 - samples/sec: 87.16\n",
            "2020-02-03 17:57:18,122 epoch 64 - iter 12/64 - loss 0.49584430 - samples/sec: 127.59\n",
            "2020-02-03 17:57:21,314 epoch 64 - iter 18/64 - loss 0.52114859 - samples/sec: 97.45\n",
            "2020-02-03 17:57:24,121 epoch 64 - iter 24/64 - loss 0.53006203 - samples/sec: 128.11\n",
            "2020-02-03 17:57:27,767 epoch 64 - iter 30/64 - loss 0.76356276 - samples/sec: 86.28\n",
            "2020-02-03 17:57:30,831 epoch 64 - iter 36/64 - loss 0.71125846 - samples/sec: 116.39\n",
            "2020-02-03 17:57:33,971 epoch 64 - iter 42/64 - loss 0.68254276 - samples/sec: 99.24\n",
            "2020-02-03 17:57:37,185 epoch 64 - iter 48/64 - loss 0.67522761 - samples/sec: 97.26\n",
            "2020-02-03 17:57:40,339 epoch 64 - iter 54/64 - loss 0.66341167 - samples/sec: 110.05\n",
            "2020-02-03 17:57:43,544 epoch 64 - iter 60/64 - loss 0.66432186 - samples/sec: 101.11\n",
            "2020-02-03 17:57:47,051 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:57:47,053 EPOCH 64 done: loss 0.6533 - lr 0.0250\n",
            "Epoch    54: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-02-03 17:57:47,057 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 17:57:47,063 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:57:48,739 epoch 65 - iter 6/64 - loss 0.41129708 - samples/sec: 114.82\n",
            "2020-02-03 17:57:51,983 epoch 65 - iter 12/64 - loss 0.53196402 - samples/sec: 99.68\n",
            "2020-02-03 17:57:55,268 epoch 65 - iter 18/64 - loss 0.50816169 - samples/sec: 103.55\n",
            "2020-02-03 17:57:58,641 epoch 65 - iter 24/64 - loss 0.50705776 - samples/sec: 108.82\n",
            "2020-02-03 17:58:02,368 epoch 65 - iter 30/64 - loss 0.79434728 - samples/sec: 79.55\n",
            "2020-02-03 17:58:05,456 epoch 65 - iter 36/64 - loss 0.75434739 - samples/sec: 108.11\n",
            "2020-02-03 17:58:09,106 epoch 65 - iter 42/64 - loss 0.70213894 - samples/sec: 89.42\n",
            "2020-02-03 17:58:12,437 epoch 65 - iter 48/64 - loss 0.67251056 - samples/sec: 105.39\n",
            "2020-02-03 17:58:15,680 epoch 65 - iter 54/64 - loss 0.64028899 - samples/sec: 94.66\n",
            "2020-02-03 17:58:18,920 epoch 65 - iter 60/64 - loss 0.61294321 - samples/sec: 105.28\n",
            "2020-02-03 17:58:21,373 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:58:21,375 EPOCH 65 done: loss 0.6076 - lr 0.0125\n",
            "2020-02-03 17:58:21,378 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 17:58:21,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:58:23,346 epoch 66 - iter 6/64 - loss 0.44533896 - samples/sec: 98.00\n",
            "2020-02-03 17:58:26,474 epoch 66 - iter 12/64 - loss 0.51194837 - samples/sec: 99.59\n",
            "2020-02-03 17:58:29,988 epoch 66 - iter 18/64 - loss 0.53413869 - samples/sec: 92.87\n",
            "2020-02-03 17:58:33,095 epoch 66 - iter 24/64 - loss 0.49449620 - samples/sec: 113.61\n",
            "2020-02-03 17:58:36,115 epoch 66 - iter 30/64 - loss 0.49280373 - samples/sec: 100.16\n",
            "2020-02-03 17:58:39,841 epoch 66 - iter 36/64 - loss 0.51940628 - samples/sec: 86.46\n",
            "2020-02-03 17:58:42,958 epoch 66 - iter 42/64 - loss 0.51464758 - samples/sec: 112.39\n",
            "2020-02-03 17:58:46,844 epoch 66 - iter 48/64 - loss 0.87975391 - samples/sec: 81.08\n",
            "2020-02-03 17:58:50,127 epoch 66 - iter 54/64 - loss 0.84087818 - samples/sec: 97.34\n",
            "2020-02-03 17:58:53,660 epoch 66 - iter 60/64 - loss 0.82263566 - samples/sec: 90.61\n",
            "2020-02-03 17:58:56,010 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:58:56,014 EPOCH 66 done: loss 0.7994 - lr 0.0125\n",
            "2020-02-03 17:58:56,015 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 17:58:56,020 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:58:57,834 epoch 67 - iter 6/64 - loss 0.51591265 - samples/sec: 106.15\n",
            "2020-02-03 17:59:01,481 epoch 67 - iter 12/64 - loss 1.73827104 - samples/sec: 86.35\n",
            "2020-02-03 17:59:04,531 epoch 67 - iter 18/64 - loss 1.32566190 - samples/sec: 93.83\n",
            "2020-02-03 17:59:07,348 epoch 67 - iter 24/64 - loss 1.10194064 - samples/sec: 130.07\n",
            "2020-02-03 17:59:10,609 epoch 67 - iter 30/64 - loss 0.95506433 - samples/sec: 103.49\n",
            "2020-02-03 17:59:13,633 epoch 67 - iter 36/64 - loss 0.86923483 - samples/sec: 119.16\n",
            "2020-02-03 17:59:17,401 epoch 67 - iter 42/64 - loss 0.82191827 - samples/sec: 81.55\n",
            "2020-02-03 17:59:20,729 epoch 67 - iter 48/64 - loss 0.78051407 - samples/sec: 107.62\n",
            "2020-02-03 17:59:23,943 epoch 67 - iter 54/64 - loss 0.75650330 - samples/sec: 100.42\n",
            "2020-02-03 17:59:27,128 epoch 67 - iter 60/64 - loss 0.74238169 - samples/sec: 98.32\n",
            "2020-02-03 17:59:29,595 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:59:29,597 EPOCH 67 done: loss 0.7241 - lr 0.0125\n",
            "2020-02-03 17:59:29,599 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 17:59:29,607 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 17:59:31,384 epoch 68 - iter 6/64 - loss 0.48232820 - samples/sec: 108.51\n",
            "2020-02-03 17:59:34,670 epoch 68 - iter 12/64 - loss 0.49046484 - samples/sec: 102.50\n",
            "2020-02-03 17:59:37,962 epoch 68 - iter 18/64 - loss 0.50606307 - samples/sec: 101.21\n",
            "2020-02-03 17:59:41,261 epoch 68 - iter 24/64 - loss 0.49714874 - samples/sec: 107.00\n",
            "2020-02-03 17:59:44,254 epoch 68 - iter 30/64 - loss 0.50439471 - samples/sec: 114.58\n",
            "2020-02-03 17:59:47,569 epoch 68 - iter 36/64 - loss 0.49839865 - samples/sec: 91.68\n",
            "2020-02-03 17:59:50,994 epoch 68 - iter 42/64 - loss 0.50316198 - samples/sec: 86.96\n",
            "2020-02-03 17:59:54,283 epoch 68 - iter 48/64 - loss 0.50588462 - samples/sec: 107.54\n",
            "2020-02-03 17:59:57,305 epoch 68 - iter 54/64 - loss 0.50086975 - samples/sec: 111.47\n",
            "2020-02-03 18:00:00,980 epoch 68 - iter 60/64 - loss 0.64950137 - samples/sec: 81.54\n",
            "2020-02-03 18:00:03,658 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:00:03,660 EPOCH 68 done: loss 0.6393 - lr 0.0125\n",
            "Epoch    58: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-02-03 18:00:03,665 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:00:03,670 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:00:05,358 epoch 69 - iter 6/64 - loss 0.65297773 - samples/sec: 114.00\n",
            "2020-02-03 18:00:08,496 epoch 69 - iter 12/64 - loss 0.55802261 - samples/sec: 104.68\n",
            "2020-02-03 18:00:11,835 epoch 69 - iter 18/64 - loss 0.55831540 - samples/sec: 101.64\n",
            "2020-02-03 18:00:15,303 epoch 69 - iter 24/64 - loss 0.79249993 - samples/sec: 93.88\n",
            "2020-02-03 18:00:18,627 epoch 69 - iter 30/64 - loss 0.71682795 - samples/sec: 95.90\n",
            "2020-02-03 18:00:22,331 epoch 69 - iter 36/64 - loss 0.69815057 - samples/sec: 82.73\n",
            "2020-02-03 18:00:25,662 epoch 69 - iter 42/64 - loss 0.66378517 - samples/sec: 94.39\n",
            "2020-02-03 18:00:28,766 epoch 69 - iter 48/64 - loss 0.63744650 - samples/sec: 107.59\n",
            "2020-02-03 18:00:32,514 epoch 69 - iter 54/64 - loss 0.61102882 - samples/sec: 82.29\n",
            "2020-02-03 18:00:35,305 epoch 69 - iter 60/64 - loss 0.58671477 - samples/sec: 129.02\n",
            "2020-02-03 18:00:38,095 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:00:38,097 EPOCH 69 done: loss 0.5897 - lr 0.0063\n",
            "2020-02-03 18:00:38,098 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 18:00:38,104 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:00:39,718 epoch 70 - iter 6/64 - loss 0.49093720 - samples/sec: 119.51\n",
            "2020-02-03 18:00:42,981 epoch 70 - iter 12/64 - loss 0.49502641 - samples/sec: 98.39\n",
            "2020-02-03 18:00:46,077 epoch 70 - iter 18/64 - loss 0.52229556 - samples/sec: 101.93\n",
            "2020-02-03 18:00:49,356 epoch 70 - iter 24/64 - loss 0.51643870 - samples/sec: 93.03\n",
            "2020-02-03 18:00:52,756 epoch 70 - iter 30/64 - loss 0.50711450 - samples/sec: 92.06\n",
            "2020-02-03 18:00:56,492 epoch 70 - iter 36/64 - loss 0.58376006 - samples/sec: 82.75\n",
            "2020-02-03 18:00:59,244 epoch 70 - iter 42/64 - loss 0.55703727 - samples/sec: 133.29\n",
            "2020-02-03 18:01:02,612 epoch 70 - iter 48/64 - loss 0.55750572 - samples/sec: 94.30\n",
            "2020-02-03 18:01:06,099 epoch 70 - iter 54/64 - loss 0.53633316 - samples/sec: 94.13\n",
            "2020-02-03 18:01:09,637 epoch 70 - iter 60/64 - loss 0.53003957 - samples/sec: 99.83\n",
            "2020-02-03 18:01:12,194 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:01:12,198 EPOCH 70 done: loss 0.5279 - lr 0.0063\n",
            "2020-02-03 18:01:12,200 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 18:01:12,206 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:01:13,981 epoch 71 - iter 6/64 - loss 0.50681786 - samples/sec: 108.38\n",
            "2020-02-03 18:01:17,571 epoch 71 - iter 12/64 - loss 0.46670007 - samples/sec: 96.99\n",
            "2020-02-03 18:01:20,637 epoch 71 - iter 18/64 - loss 0.46547103 - samples/sec: 108.99\n",
            "2020-02-03 18:01:23,654 epoch 71 - iter 24/64 - loss 0.47439492 - samples/sec: 112.69\n",
            "2020-02-03 18:01:26,945 epoch 71 - iter 30/64 - loss 0.46446540 - samples/sec: 108.09\n",
            "2020-02-03 18:01:30,415 epoch 71 - iter 36/64 - loss 0.47540791 - samples/sec: 103.50\n",
            "2020-02-03 18:01:33,984 epoch 71 - iter 42/64 - loss 0.58852107 - samples/sec: 88.97\n",
            "2020-02-03 18:01:37,710 epoch 71 - iter 48/64 - loss 0.57366149 - samples/sec: 90.76\n",
            "2020-02-03 18:01:40,899 epoch 71 - iter 54/64 - loss 0.55381993 - samples/sec: 102.93\n",
            "2020-02-03 18:01:43,949 epoch 71 - iter 60/64 - loss 0.54073696 - samples/sec: 103.67\n",
            "2020-02-03 18:01:46,732 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:01:46,738 EPOCH 71 done: loss 0.5362 - lr 0.0063\n",
            "2020-02-03 18:01:46,742 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:01:46,746 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:01:48,679 epoch 72 - iter 6/64 - loss 0.53587182 - samples/sec: 99.56\n",
            "2020-02-03 18:01:51,542 epoch 72 - iter 12/64 - loss 0.44445599 - samples/sec: 124.03\n",
            "2020-02-03 18:01:54,833 epoch 72 - iter 18/64 - loss 0.47174742 - samples/sec: 102.18\n",
            "2020-02-03 18:01:57,996 epoch 72 - iter 24/64 - loss 0.46822147 - samples/sec: 111.22\n",
            "2020-02-03 18:02:01,113 epoch 72 - iter 30/64 - loss 0.47829610 - samples/sec: 101.58\n",
            "2020-02-03 18:02:04,553 epoch 72 - iter 36/64 - loss 0.75067752 - samples/sec: 90.55\n",
            "2020-02-03 18:02:07,497 epoch 72 - iter 42/64 - loss 0.70793365 - samples/sec: 112.30\n",
            "2020-02-03 18:02:10,669 epoch 72 - iter 48/64 - loss 0.66469771 - samples/sec: 102.62\n",
            "2020-02-03 18:02:13,744 epoch 72 - iter 54/64 - loss 0.64438987 - samples/sec: 108.82\n",
            "2020-02-03 18:02:16,888 epoch 72 - iter 60/64 - loss 0.62669398 - samples/sec: 104.39\n",
            "2020-02-03 18:02:19,879 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:02:19,882 EPOCH 72 done: loss 0.6183 - lr 0.0063\n",
            "2020-02-03 18:02:19,884 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:02:19,888 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:02:21,650 epoch 73 - iter 6/64 - loss 0.53755866 - samples/sec: 109.29\n",
            "2020-02-03 18:02:24,895 epoch 73 - iter 12/64 - loss 0.52337894 - samples/sec: 98.52\n",
            "2020-02-03 18:02:28,068 epoch 73 - iter 18/64 - loss 0.95865834 - samples/sec: 98.30\n",
            "2020-02-03 18:02:31,067 epoch 73 - iter 24/64 - loss 0.82624092 - samples/sec: 113.14\n",
            "2020-02-03 18:02:34,738 epoch 73 - iter 30/64 - loss 0.75043436 - samples/sec: 81.94\n",
            "2020-02-03 18:02:37,690 epoch 73 - iter 36/64 - loss 0.70342114 - samples/sec: 110.12\n",
            "2020-02-03 18:02:41,006 epoch 73 - iter 42/64 - loss 0.66705892 - samples/sec: 96.08\n",
            "2020-02-03 18:02:44,363 epoch 73 - iter 48/64 - loss 0.65235660 - samples/sec: 93.83\n",
            "2020-02-03 18:02:47,920 epoch 73 - iter 54/64 - loss 0.62968736 - samples/sec: 95.39\n",
            "2020-02-03 18:02:50,949 epoch 73 - iter 60/64 - loss 0.60822266 - samples/sec: 106.89\n",
            "2020-02-03 18:02:53,694 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:02:53,696 EPOCH 73 done: loss 0.5925 - lr 0.0063\n",
            "2020-02-03 18:02:53,698 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:02:53,706 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:02:55,571 epoch 74 - iter 6/64 - loss 1.06630856 - samples/sec: 103.23\n",
            "2020-02-03 18:02:58,586 epoch 74 - iter 12/64 - loss 0.73088304 - samples/sec: 112.62\n",
            "2020-02-03 18:03:02,008 epoch 74 - iter 18/64 - loss 0.66758310 - samples/sec: 91.10\n",
            "2020-02-03 18:03:05,020 epoch 74 - iter 24/64 - loss 0.58978330 - samples/sec: 119.53\n",
            "2020-02-03 18:03:07,812 epoch 74 - iter 30/64 - loss 0.53959735 - samples/sec: 121.13\n",
            "2020-02-03 18:03:10,960 epoch 74 - iter 36/64 - loss 0.54235854 - samples/sec: 100.17\n",
            "2020-02-03 18:03:14,241 epoch 74 - iter 42/64 - loss 0.52332577 - samples/sec: 98.16\n",
            "2020-02-03 18:03:17,682 epoch 74 - iter 48/64 - loss 0.51918865 - samples/sec: 82.83\n",
            "2020-02-03 18:03:21,153 epoch 74 - iter 54/64 - loss 0.50399493 - samples/sec: 97.72\n",
            "2020-02-03 18:03:24,046 epoch 74 - iter 60/64 - loss 0.50092702 - samples/sec: 108.44\n",
            "2020-02-03 18:03:26,514 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:03:26,516 EPOCH 74 done: loss 0.4900 - lr 0.0063\n",
            "2020-02-03 18:03:26,521 BAD EPOCHS (no improvement): 0\n",
            "2020-02-03 18:03:26,527 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:03:28,685 epoch 75 - iter 6/64 - loss 2.16524170 - samples/sec: 89.22\n",
            "2020-02-03 18:03:32,448 epoch 75 - iter 12/64 - loss 1.33165832 - samples/sec: 81.75\n",
            "2020-02-03 18:03:35,378 epoch 75 - iter 18/64 - loss 1.04566187 - samples/sec: 112.17\n",
            "2020-02-03 18:03:38,567 epoch 75 - iter 24/64 - loss 0.91902782 - samples/sec: 109.88\n",
            "2020-02-03 18:03:41,947 epoch 75 - iter 30/64 - loss 0.82478686 - samples/sec: 96.99\n",
            "2020-02-03 18:03:45,163 epoch 75 - iter 36/64 - loss 0.76367467 - samples/sec: 95.93\n",
            "2020-02-03 18:03:48,194 epoch 75 - iter 42/64 - loss 0.73310422 - samples/sec: 118.61\n",
            "2020-02-03 18:03:51,142 epoch 75 - iter 48/64 - loss 0.70591343 - samples/sec: 116.28\n",
            "2020-02-03 18:03:54,306 epoch 75 - iter 54/64 - loss 0.67958916 - samples/sec: 109.83\n",
            "2020-02-03 18:03:57,383 epoch 75 - iter 60/64 - loss 0.66950822 - samples/sec: 103.10\n",
            "2020-02-03 18:04:00,077 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:04:00,079 EPOCH 75 done: loss 0.6556 - lr 0.0063\n",
            "2020-02-03 18:04:00,080 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:04:00,084 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:04:02,003 epoch 76 - iter 6/64 - loss 0.47905989 - samples/sec: 100.26\n",
            "2020-02-03 18:04:05,098 epoch 76 - iter 12/64 - loss 0.44263529 - samples/sec: 106.96\n",
            "2020-02-03 18:04:08,416 epoch 76 - iter 18/64 - loss 0.44234378 - samples/sec: 95.39\n",
            "2020-02-03 18:04:11,403 epoch 76 - iter 24/64 - loss 0.45718534 - samples/sec: 114.38\n",
            "2020-02-03 18:04:14,509 epoch 76 - iter 30/64 - loss 0.48789221 - samples/sec: 112.97\n",
            "2020-02-03 18:04:17,797 epoch 76 - iter 36/64 - loss 0.46717517 - samples/sec: 102.34\n",
            "2020-02-03 18:04:21,262 epoch 76 - iter 42/64 - loss 0.68767091 - samples/sec: 88.85\n",
            "2020-02-03 18:04:24,243 epoch 76 - iter 48/64 - loss 0.66406633 - samples/sec: 114.39\n",
            "2020-02-03 18:04:27,294 epoch 76 - iter 54/64 - loss 0.63794862 - samples/sec: 119.33\n",
            "2020-02-03 18:04:31,090 epoch 76 - iter 60/64 - loss 0.62388633 - samples/sec: 77.44\n",
            "2020-02-03 18:04:33,400 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:04:33,403 EPOCH 76 done: loss 0.6133 - lr 0.0063\n",
            "2020-02-03 18:04:33,410 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:04:33,419 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:04:35,287 epoch 77 - iter 6/64 - loss 0.30604258 - samples/sec: 103.15\n",
            "2020-02-03 18:04:38,533 epoch 77 - iter 12/64 - loss 0.35436952 - samples/sec: 99.90\n",
            "2020-02-03 18:04:41,529 epoch 77 - iter 18/64 - loss 0.37983792 - samples/sec: 114.41\n",
            "2020-02-03 18:04:44,886 epoch 77 - iter 24/64 - loss 0.42516340 - samples/sec: 89.90\n",
            "2020-02-03 18:04:48,660 epoch 77 - iter 30/64 - loss 0.44705727 - samples/sec: 88.96\n",
            "2020-02-03 18:04:51,523 epoch 77 - iter 36/64 - loss 0.45082953 - samples/sec: 116.66\n",
            "2020-02-03 18:04:54,875 epoch 77 - iter 42/64 - loss 0.46071329 - samples/sec: 100.02\n",
            "2020-02-03 18:04:57,815 epoch 77 - iter 48/64 - loss 0.45534210 - samples/sec: 117.00\n",
            "2020-02-03 18:05:00,918 epoch 77 - iter 54/64 - loss 0.47362280 - samples/sec: 106.87\n",
            "2020-02-03 18:05:03,881 epoch 77 - iter 60/64 - loss 0.60216983 - samples/sec: 115.69\n",
            "2020-02-03 18:05:06,830 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:05:06,832 EPOCH 77 done: loss 0.5981 - lr 0.0063\n",
            "2020-02-03 18:05:06,834 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:05:06,841 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:05:08,671 epoch 78 - iter 6/64 - loss 0.44298504 - samples/sec: 105.16\n",
            "2020-02-03 18:05:11,751 epoch 78 - iter 12/64 - loss 0.45818474 - samples/sec: 108.37\n",
            "2020-02-03 18:05:14,689 epoch 78 - iter 18/64 - loss 0.45725882 - samples/sec: 118.54\n",
            "2020-02-03 18:05:18,234 epoch 78 - iter 24/64 - loss 0.46499817 - samples/sec: 94.83\n",
            "2020-02-03 18:05:21,246 epoch 78 - iter 30/64 - loss 0.48476321 - samples/sec: 106.96\n",
            "2020-02-03 18:05:24,136 epoch 78 - iter 36/64 - loss 0.47462230 - samples/sec: 115.13\n",
            "2020-02-03 18:05:27,355 epoch 78 - iter 42/64 - loss 0.47397666 - samples/sec: 100.22\n",
            "2020-02-03 18:05:30,444 epoch 78 - iter 48/64 - loss 0.47336566 - samples/sec: 107.93\n",
            "2020-02-03 18:05:34,029 epoch 78 - iter 54/64 - loss 0.59960235 - samples/sec: 88.28\n",
            "2020-02-03 18:05:37,831 epoch 78 - iter 60/64 - loss 0.58341950 - samples/sec: 77.03\n",
            "2020-02-03 18:05:40,437 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:05:40,440 EPOCH 78 done: loss 0.5741 - lr 0.0063\n",
            "Epoch    68: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-02-03 18:05:40,447 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:05:40,453 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:05:42,362 epoch 79 - iter 6/64 - loss 0.64494075 - samples/sec: 100.70\n",
            "2020-02-03 18:05:45,895 epoch 79 - iter 12/64 - loss 0.53080380 - samples/sec: 86.30\n",
            "2020-02-03 18:05:49,953 epoch 79 - iter 18/64 - loss 0.53764676 - samples/sec: 78.51\n",
            "2020-02-03 18:05:52,840 epoch 79 - iter 24/64 - loss 0.52113186 - samples/sec: 102.89\n",
            "2020-02-03 18:05:56,093 epoch 79 - iter 30/64 - loss 0.51379858 - samples/sec: 99.90\n",
            "2020-02-03 18:05:59,340 epoch 79 - iter 36/64 - loss 0.70226633 - samples/sec: 104.42\n",
            "2020-02-03 18:06:02,311 epoch 79 - iter 42/64 - loss 0.65207155 - samples/sec: 115.37\n",
            "2020-02-03 18:06:05,480 epoch 79 - iter 48/64 - loss 0.62196519 - samples/sec: 103.20\n",
            "2020-02-03 18:06:08,545 epoch 79 - iter 54/64 - loss 0.61184675 - samples/sec: 109.50\n",
            "2020-02-03 18:06:11,671 epoch 79 - iter 60/64 - loss 0.58603972 - samples/sec: 108.03\n",
            "2020-02-03 18:06:14,535 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:06:14,541 EPOCH 79 done: loss 0.5786 - lr 0.0031\n",
            "2020-02-03 18:06:14,545 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:06:14,554 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:06:16,372 epoch 80 - iter 6/64 - loss 0.46799802 - samples/sec: 105.84\n",
            "2020-02-03 18:06:19,604 epoch 80 - iter 12/64 - loss 0.46128365 - samples/sec: 111.19\n",
            "2020-02-03 18:06:22,851 epoch 80 - iter 18/64 - loss 0.44359809 - samples/sec: 94.07\n",
            "2020-02-03 18:06:26,250 epoch 80 - iter 24/64 - loss 1.01287226 - samples/sec: 92.21\n",
            "2020-02-03 18:06:29,453 epoch 80 - iter 30/64 - loss 0.89351507 - samples/sec: 102.16\n",
            "2020-02-03 18:06:32,773 epoch 80 - iter 36/64 - loss 0.83912924 - samples/sec: 90.96\n",
            "2020-02-03 18:06:35,998 epoch 80 - iter 42/64 - loss 0.78989671 - samples/sec: 111.42\n",
            "2020-02-03 18:06:39,706 epoch 80 - iter 48/64 - loss 0.74940132 - samples/sec: 84.37\n",
            "2020-02-03 18:06:43,037 epoch 80 - iter 54/64 - loss 0.73051483 - samples/sec: 106.35\n",
            "2020-02-03 18:06:46,546 epoch 80 - iter 60/64 - loss 0.69871237 - samples/sec: 100.85\n",
            "2020-02-03 18:06:49,147 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:06:49,149 EPOCH 80 done: loss 0.6939 - lr 0.0031\n",
            "2020-02-03 18:06:49,153 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:06:49,160 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:06:51,279 epoch 81 - iter 6/64 - loss 0.55166633 - samples/sec: 90.73\n",
            "2020-02-03 18:06:54,917 epoch 81 - iter 12/64 - loss 0.55136689 - samples/sec: 94.45\n",
            "2020-02-03 18:06:57,982 epoch 81 - iter 18/64 - loss 0.51405636 - samples/sec: 103.34\n",
            "2020-02-03 18:07:01,279 epoch 81 - iter 24/64 - loss 0.48420224 - samples/sec: 92.41\n",
            "2020-02-03 18:07:04,325 epoch 81 - iter 30/64 - loss 0.47981934 - samples/sec: 110.24\n",
            "2020-02-03 18:07:07,311 epoch 81 - iter 36/64 - loss 0.46193143 - samples/sec: 108.51\n",
            "2020-02-03 18:07:10,339 epoch 81 - iter 42/64 - loss 0.45205930 - samples/sec: 110.96\n",
            "2020-02-03 18:07:13,756 epoch 81 - iter 48/64 - loss 0.53408315 - samples/sec: 95.58\n",
            "2020-02-03 18:07:17,523 epoch 81 - iter 54/64 - loss 0.52538716 - samples/sec: 84.85\n",
            "2020-02-03 18:07:20,802 epoch 81 - iter 60/64 - loss 0.53308384 - samples/sec: 102.78\n",
            "2020-02-03 18:07:23,298 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:07:23,302 EPOCH 81 done: loss 0.5217 - lr 0.0031\n",
            "2020-02-03 18:07:23,304 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:07:23,309 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:07:25,205 epoch 82 - iter 6/64 - loss 0.39770672 - samples/sec: 101.52\n",
            "2020-02-03 18:07:28,571 epoch 82 - iter 12/64 - loss 0.90769398 - samples/sec: 93.92\n",
            "2020-02-03 18:07:31,755 epoch 82 - iter 18/64 - loss 0.72969235 - samples/sec: 109.02\n",
            "2020-02-03 18:07:35,139 epoch 82 - iter 24/64 - loss 0.68502199 - samples/sec: 97.16\n",
            "2020-02-03 18:07:38,112 epoch 82 - iter 30/64 - loss 0.66244166 - samples/sec: 116.18\n",
            "2020-02-03 18:07:41,456 epoch 82 - iter 36/64 - loss 0.62397685 - samples/sec: 99.36\n",
            "2020-02-03 18:07:44,525 epoch 82 - iter 42/64 - loss 0.58851204 - samples/sec: 109.43\n",
            "2020-02-03 18:07:48,088 epoch 82 - iter 48/64 - loss 0.58678051 - samples/sec: 93.29\n",
            "2020-02-03 18:07:50,915 epoch 82 - iter 54/64 - loss 0.58251363 - samples/sec: 135.93\n",
            "2020-02-03 18:07:54,587 epoch 82 - iter 60/64 - loss 0.57862627 - samples/sec: 81.74\n",
            "2020-02-03 18:07:57,259 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:07:57,262 EPOCH 82 done: loss 0.5639 - lr 0.0031\n",
            "Epoch    72: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-02-03 18:07:57,264 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:07:57,272 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:07:59,023 epoch 83 - iter 6/64 - loss 0.58871234 - samples/sec: 109.85\n",
            "2020-02-03 18:08:02,895 epoch 83 - iter 12/64 - loss 0.57135929 - samples/sec: 77.98\n",
            "2020-02-03 18:08:05,888 epoch 83 - iter 18/64 - loss 0.53579998 - samples/sec: 121.60\n",
            "2020-02-03 18:08:09,168 epoch 83 - iter 24/64 - loss 0.58914859 - samples/sec: 92.94\n",
            "2020-02-03 18:08:12,484 epoch 83 - iter 30/64 - loss 0.56595100 - samples/sec: 101.02\n",
            "2020-02-03 18:08:15,834 epoch 83 - iter 36/64 - loss 0.53508301 - samples/sec: 94.14\n",
            "2020-02-03 18:08:18,862 epoch 83 - iter 42/64 - loss 0.51306313 - samples/sec: 118.70\n",
            "2020-02-03 18:08:22,317 epoch 83 - iter 48/64 - loss 0.52021173 - samples/sec: 89.51\n",
            "2020-02-03 18:08:25,912 epoch 83 - iter 54/64 - loss 0.51893706 - samples/sec: 83.78\n",
            "2020-02-03 18:08:28,833 epoch 83 - iter 60/64 - loss 0.51175846 - samples/sec: 106.50\n",
            "2020-02-03 18:08:31,247 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:08:31,252 EPOCH 83 done: loss 0.5055 - lr 0.0016\n",
            "2020-02-03 18:08:31,254 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:08:31,259 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:08:33,108 epoch 84 - iter 6/64 - loss 0.40542612 - samples/sec: 104.18\n",
            "2020-02-03 18:08:36,714 epoch 84 - iter 12/64 - loss 0.43182461 - samples/sec: 87.34\n",
            "2020-02-03 18:08:40,072 epoch 84 - iter 18/64 - loss 0.43469938 - samples/sec: 98.83\n",
            "2020-02-03 18:08:43,495 epoch 84 - iter 24/64 - loss 0.43860834 - samples/sec: 90.54\n",
            "2020-02-03 18:08:46,710 epoch 84 - iter 30/64 - loss 0.46946536 - samples/sec: 105.75\n",
            "2020-02-03 18:08:50,142 epoch 84 - iter 36/64 - loss 0.56860425 - samples/sec: 92.36\n",
            "2020-02-03 18:08:53,369 epoch 84 - iter 42/64 - loss 0.54614641 - samples/sec: 99.86\n",
            "2020-02-03 18:08:56,389 epoch 84 - iter 48/64 - loss 0.52047522 - samples/sec: 111.89\n",
            "2020-02-03 18:08:59,383 epoch 84 - iter 54/64 - loss 0.49911941 - samples/sec: 113.75\n",
            "2020-02-03 18:09:02,412 epoch 84 - iter 60/64 - loss 0.49309418 - samples/sec: 112.11\n",
            "2020-02-03 18:09:05,018 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:09:05,021 EPOCH 84 done: loss 0.4913 - lr 0.0016\n",
            "2020-02-03 18:09:05,023 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:09:05,029 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:09:06,901 epoch 85 - iter 6/64 - loss 0.51052489 - samples/sec: 102.66\n",
            "2020-02-03 18:09:10,041 epoch 85 - iter 12/64 - loss 0.49533642 - samples/sec: 104.34\n",
            "2020-02-03 18:09:12,805 epoch 85 - iter 18/64 - loss 0.43689419 - samples/sec: 123.49\n",
            "2020-02-03 18:09:16,036 epoch 85 - iter 24/64 - loss 0.47662929 - samples/sec: 95.18\n",
            "2020-02-03 18:09:19,382 epoch 85 - iter 30/64 - loss 0.44890038 - samples/sec: 99.25\n",
            "2020-02-03 18:09:22,371 epoch 85 - iter 36/64 - loss 0.48554415 - samples/sec: 113.48\n",
            "2020-02-03 18:09:25,375 epoch 85 - iter 42/64 - loss 0.49668785 - samples/sec: 107.18\n",
            "2020-02-03 18:09:28,882 epoch 85 - iter 48/64 - loss 0.67788625 - samples/sec: 87.05\n",
            "2020-02-03 18:09:32,364 epoch 85 - iter 54/64 - loss 0.64726884 - samples/sec: 88.15\n",
            "2020-02-03 18:09:35,190 epoch 85 - iter 60/64 - loss 0.61785002 - samples/sec: 119.38\n",
            "2020-02-03 18:09:37,671 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:09:37,672 EPOCH 85 done: loss 0.6009 - lr 0.0016\n",
            "2020-02-03 18:09:37,675 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:09:37,679 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:09:39,618 epoch 86 - iter 6/64 - loss 0.44916288 - samples/sec: 99.51\n",
            "2020-02-03 18:09:43,098 epoch 86 - iter 12/64 - loss 0.47070741 - samples/sec: 92.23\n",
            "2020-02-03 18:09:46,585 epoch 86 - iter 18/64 - loss 0.47704372 - samples/sec: 92.40\n",
            "2020-02-03 18:09:49,826 epoch 86 - iter 24/64 - loss 0.46992679 - samples/sec: 109.82\n",
            "2020-02-03 18:09:53,190 epoch 86 - iter 30/64 - loss 0.49563835 - samples/sec: 93.42\n",
            "2020-02-03 18:09:56,239 epoch 86 - iter 36/64 - loss 0.51031596 - samples/sec: 104.64\n",
            "2020-02-03 18:09:59,312 epoch 86 - iter 42/64 - loss 0.52387194 - samples/sec: 103.45\n",
            "2020-02-03 18:10:01,917 epoch 86 - iter 48/64 - loss 0.51593835 - samples/sec: 127.93\n",
            "2020-02-03 18:10:04,827 epoch 86 - iter 54/64 - loss 0.49964568 - samples/sec: 120.23\n",
            "2020-02-03 18:10:08,126 epoch 86 - iter 60/64 - loss 0.63076501 - samples/sec: 91.88\n",
            "2020-02-03 18:10:10,334 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:10:10,335 EPOCH 86 done: loss 0.6136 - lr 0.0016\n",
            "Epoch    76: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-02-03 18:10:10,337 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:10:10,343 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:10:11,818 epoch 87 - iter 6/64 - loss 0.41367973 - samples/sec: 130.45\n",
            "2020-02-03 18:10:14,838 epoch 87 - iter 12/64 - loss 0.38899200 - samples/sec: 117.73\n",
            "2020-02-03 18:10:18,020 epoch 87 - iter 18/64 - loss 0.37278951 - samples/sec: 114.71\n",
            "2020-02-03 18:10:20,730 epoch 87 - iter 24/64 - loss 0.39069614 - samples/sec: 128.68\n",
            "2020-02-03 18:10:23,958 epoch 87 - iter 30/64 - loss 0.51750001 - samples/sec: 95.00\n",
            "2020-02-03 18:10:26,627 epoch 87 - iter 36/64 - loss 0.51490125 - samples/sec: 132.09\n",
            "2020-02-03 18:10:30,009 epoch 87 - iter 42/64 - loss 0.51731983 - samples/sec: 92.25\n",
            "2020-02-03 18:10:32,855 epoch 87 - iter 48/64 - loss 0.51095548 - samples/sec: 110.76\n",
            "2020-02-03 18:10:36,101 epoch 87 - iter 54/64 - loss 0.52623563 - samples/sec: 106.30\n",
            "2020-02-03 18:10:39,092 epoch 87 - iter 60/64 - loss 0.51695947 - samples/sec: 107.76\n",
            "2020-02-03 18:10:41,935 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:10:41,940 EPOCH 87 done: loss 0.5114 - lr 0.0008\n",
            "2020-02-03 18:10:41,944 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:10:41,952 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:10:43,912 epoch 88 - iter 6/64 - loss 0.45270158 - samples/sec: 98.17\n",
            "2020-02-03 18:10:47,427 epoch 88 - iter 12/64 - loss 0.45975989 - samples/sec: 95.87\n",
            "2020-02-03 18:10:50,457 epoch 88 - iter 18/64 - loss 0.46914194 - samples/sec: 118.01\n",
            "2020-02-03 18:10:53,786 epoch 88 - iter 24/64 - loss 0.61202816 - samples/sec: 94.43\n",
            "2020-02-03 18:10:56,796 epoch 88 - iter 30/64 - loss 0.60688289 - samples/sec: 106.90\n",
            "2020-02-03 18:10:59,657 epoch 88 - iter 36/64 - loss 0.59227787 - samples/sec: 115.84\n",
            "2020-02-03 18:11:02,535 epoch 88 - iter 42/64 - loss 0.57765896 - samples/sec: 121.43\n",
            "2020-02-03 18:11:05,641 epoch 88 - iter 48/64 - loss 0.56339141 - samples/sec: 107.20\n",
            "2020-02-03 18:11:08,665 epoch 88 - iter 54/64 - loss 0.55560723 - samples/sec: 105.24\n",
            "2020-02-03 18:11:11,617 epoch 88 - iter 60/64 - loss 0.53911579 - samples/sec: 110.42\n",
            "2020-02-03 18:11:13,957 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:11:13,959 EPOCH 88 done: loss 0.5285 - lr 0.0008\n",
            "2020-02-03 18:11:13,962 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:11:13,968 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:11:15,744 epoch 89 - iter 6/64 - loss 0.38586428 - samples/sec: 108.31\n",
            "2020-02-03 18:11:19,117 epoch 89 - iter 12/64 - loss 0.36822607 - samples/sec: 102.78\n",
            "2020-02-03 18:11:22,306 epoch 89 - iter 18/64 - loss 0.42755856 - samples/sec: 115.00\n",
            "2020-02-03 18:11:25,490 epoch 89 - iter 24/64 - loss 0.41741588 - samples/sec: 108.16\n",
            "2020-02-03 18:11:28,507 epoch 89 - iter 30/64 - loss 0.44678228 - samples/sec: 106.09\n",
            "2020-02-03 18:11:31,464 epoch 89 - iter 36/64 - loss 0.46058575 - samples/sec: 103.90\n",
            "2020-02-03 18:11:34,761 epoch 89 - iter 42/64 - loss 0.46184719 - samples/sec: 96.12\n",
            "2020-02-03 18:11:37,765 epoch 89 - iter 48/64 - loss 0.47824007 - samples/sec: 115.51\n",
            "2020-02-03 18:11:40,693 epoch 89 - iter 54/64 - loss 0.47813430 - samples/sec: 105.51\n",
            "2020-02-03 18:11:43,942 epoch 89 - iter 60/64 - loss 0.57292302 - samples/sec: 94.16\n",
            "2020-02-03 18:11:46,419 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:11:46,421 EPOCH 89 done: loss 0.5580 - lr 0.0008\n",
            "2020-02-03 18:11:46,426 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:11:46,433 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:11:48,124 epoch 90 - iter 6/64 - loss 0.29320940 - samples/sec: 113.83\n",
            "2020-02-03 18:11:51,537 epoch 90 - iter 12/64 - loss 0.35323625 - samples/sec: 101.14\n",
            "2020-02-03 18:11:55,147 epoch 90 - iter 18/64 - loss 0.35478117 - samples/sec: 96.67\n",
            "2020-02-03 18:11:58,629 epoch 90 - iter 24/64 - loss 0.43089157 - samples/sec: 88.84\n",
            "2020-02-03 18:12:01,582 epoch 90 - iter 30/64 - loss 0.45225154 - samples/sec: 110.11\n",
            "2020-02-03 18:12:04,781 epoch 90 - iter 36/64 - loss 0.47465642 - samples/sec: 101.09\n",
            "2020-02-03 18:12:07,502 epoch 90 - iter 42/64 - loss 0.46131350 - samples/sec: 118.47\n",
            "2020-02-03 18:12:10,501 epoch 90 - iter 48/64 - loss 0.56049763 - samples/sec: 108.06\n",
            "2020-02-03 18:12:13,420 epoch 90 - iter 54/64 - loss 0.53928597 - samples/sec: 112.13\n",
            "2020-02-03 18:12:16,688 epoch 90 - iter 60/64 - loss 0.54941683 - samples/sec: 97.40\n",
            "2020-02-03 18:12:19,023 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:12:19,025 EPOCH 90 done: loss 0.5450 - lr 0.0008\n",
            "Epoch    80: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-02-03 18:12:19,026 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:12:19,030 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:12:20,640 epoch 91 - iter 6/64 - loss 0.45568515 - samples/sec: 119.52\n",
            "2020-02-03 18:12:24,162 epoch 91 - iter 12/64 - loss 1.59482369 - samples/sec: 86.22\n",
            "2020-02-03 18:12:26,830 epoch 91 - iter 18/64 - loss 1.18802653 - samples/sec: 115.95\n",
            "2020-02-03 18:12:29,874 epoch 91 - iter 24/64 - loss 1.06063810 - samples/sec: 112.89\n",
            "2020-02-03 18:12:32,759 epoch 91 - iter 30/64 - loss 0.96975597 - samples/sec: 113.41\n",
            "2020-02-03 18:12:35,693 epoch 91 - iter 36/64 - loss 0.88576927 - samples/sec: 110.78\n",
            "2020-02-03 18:12:38,508 epoch 91 - iter 42/64 - loss 0.82289582 - samples/sec: 112.12\n",
            "2020-02-03 18:12:41,783 epoch 91 - iter 48/64 - loss 0.77034285 - samples/sec: 92.12\n",
            "2020-02-03 18:12:44,951 epoch 91 - iter 54/64 - loss 0.72557069 - samples/sec: 98.09\n",
            "2020-02-03 18:12:47,646 epoch 91 - iter 60/64 - loss 0.68816802 - samples/sec: 147.95\n",
            "2020-02-03 18:12:49,930 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:12:49,932 EPOCH 91 done: loss 0.6806 - lr 0.0004\n",
            "2020-02-03 18:12:49,933 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:12:49,940 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:12:51,922 epoch 92 - iter 6/64 - loss 0.52265337 - samples/sec: 97.06\n",
            "2020-02-03 18:12:55,280 epoch 92 - iter 12/64 - loss 0.45894156 - samples/sec: 98.61\n",
            "2020-02-03 18:12:58,193 epoch 92 - iter 18/64 - loss 0.45759099 - samples/sec: 112.75\n",
            "2020-02-03 18:13:01,650 epoch 92 - iter 24/64 - loss 0.45204060 - samples/sec: 89.43\n",
            "2020-02-03 18:13:04,689 epoch 92 - iter 30/64 - loss 0.47083403 - samples/sec: 105.19\n",
            "2020-02-03 18:13:07,548 epoch 92 - iter 36/64 - loss 0.46119600 - samples/sec: 130.80\n",
            "2020-02-03 18:13:10,501 epoch 92 - iter 42/64 - loss 0.46410658 - samples/sec: 110.22\n",
            "2020-02-03 18:13:13,593 epoch 92 - iter 48/64 - loss 0.59761037 - samples/sec: 96.81\n",
            "2020-02-03 18:13:16,525 epoch 92 - iter 54/64 - loss 0.57608576 - samples/sec: 107.08\n",
            "2020-02-03 18:13:19,267 epoch 92 - iter 60/64 - loss 0.56505407 - samples/sec: 133.11\n",
            "2020-02-03 18:13:21,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:13:21,691 EPOCH 92 done: loss 0.5502 - lr 0.0004\n",
            "2020-02-03 18:13:21,695 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:13:21,702 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:13:23,386 epoch 93 - iter 6/64 - loss 0.45999310 - samples/sec: 114.29\n",
            "2020-02-03 18:13:26,107 epoch 93 - iter 12/64 - loss 0.38160729 - samples/sec: 127.24\n",
            "2020-02-03 18:13:29,088 epoch 93 - iter 18/64 - loss 0.37769549 - samples/sec: 109.52\n",
            "2020-02-03 18:13:32,041 epoch 93 - iter 24/64 - loss 0.38959170 - samples/sec: 116.23\n",
            "2020-02-03 18:13:35,836 epoch 93 - iter 30/64 - loss 0.41722376 - samples/sec: 74.35\n",
            "2020-02-03 18:13:38,752 epoch 93 - iter 36/64 - loss 0.42488681 - samples/sec: 112.05\n",
            "2020-02-03 18:13:41,707 epoch 93 - iter 42/64 - loss 0.42058724 - samples/sec: 109.25\n",
            "2020-02-03 18:13:44,305 epoch 93 - iter 48/64 - loss 0.42648841 - samples/sec: 120.72\n",
            "2020-02-03 18:13:47,598 epoch 93 - iter 54/64 - loss 0.60675832 - samples/sec: 97.45\n",
            "2020-02-03 18:13:50,415 epoch 93 - iter 60/64 - loss 0.59365545 - samples/sec: 117.83\n",
            "2020-02-03 18:13:52,952 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:13:52,957 EPOCH 93 done: loss 0.5905 - lr 0.0004\n",
            "2020-02-03 18:13:52,962 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:13:52,969 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:13:54,823 epoch 94 - iter 6/64 - loss 0.46190273 - samples/sec: 103.76\n",
            "2020-02-03 18:13:57,982 epoch 94 - iter 12/64 - loss 0.46354208 - samples/sec: 109.75\n",
            "2020-02-03 18:14:00,988 epoch 94 - iter 18/64 - loss 0.49685046 - samples/sec: 113.59\n",
            "2020-02-03 18:14:04,231 epoch 94 - iter 24/64 - loss 0.50255869 - samples/sec: 112.98\n",
            "2020-02-03 18:14:06,890 epoch 94 - iter 30/64 - loss 0.47587795 - samples/sec: 131.95\n",
            "2020-02-03 18:14:09,763 epoch 94 - iter 36/64 - loss 0.79945205 - samples/sec: 114.91\n",
            "2020-02-03 18:14:12,791 epoch 94 - iter 42/64 - loss 0.74737521 - samples/sec: 111.11\n",
            "2020-02-03 18:14:15,914 epoch 94 - iter 48/64 - loss 0.71755510 - samples/sec: 99.95\n",
            "2020-02-03 18:14:19,288 epoch 94 - iter 54/64 - loss 0.68650887 - samples/sec: 84.84\n",
            "2020-02-03 18:14:22,127 epoch 94 - iter 60/64 - loss 0.66070499 - samples/sec: 117.89\n",
            "2020-02-03 18:14:24,343 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:14:24,345 EPOCH 94 done: loss 0.6534 - lr 0.0004\n",
            "Epoch    84: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-02-03 18:14:24,347 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:14:24,354 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:14:25,945 epoch 95 - iter 6/64 - loss 0.51618726 - samples/sec: 121.13\n",
            "2020-02-03 18:14:28,675 epoch 95 - iter 12/64 - loss 0.49447936 - samples/sec: 118.04\n",
            "2020-02-03 18:14:31,730 epoch 95 - iter 18/64 - loss 0.48217401 - samples/sec: 104.87\n",
            "2020-02-03 18:14:34,425 epoch 95 - iter 24/64 - loss 0.48385628 - samples/sec: 121.25\n",
            "2020-02-03 18:14:37,235 epoch 95 - iter 30/64 - loss 0.46865025 - samples/sec: 113.95\n",
            "2020-02-03 18:14:40,267 epoch 95 - iter 36/64 - loss 0.65291522 - samples/sec: 111.77\n",
            "2020-02-03 18:14:43,747 epoch 95 - iter 42/64 - loss 0.64292787 - samples/sec: 84.65\n",
            "2020-02-03 18:14:47,057 epoch 95 - iter 48/64 - loss 0.60299044 - samples/sec: 96.56\n",
            "2020-02-03 18:14:50,026 epoch 95 - iter 54/64 - loss 0.58991307 - samples/sec: 116.13\n",
            "2020-02-03 18:14:52,769 epoch 95 - iter 60/64 - loss 0.56699605 - samples/sec: 119.62\n",
            "2020-02-03 18:14:55,195 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:14:55,200 EPOCH 95 done: loss 0.5596 - lr 0.0002\n",
            "2020-02-03 18:14:55,204 BAD EPOCHS (no improvement): 1\n",
            "2020-02-03 18:14:55,210 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:14:57,135 epoch 96 - iter 6/64 - loss 0.47180743 - samples/sec: 100.00\n",
            "2020-02-03 18:15:00,089 epoch 96 - iter 12/64 - loss 0.44988508 - samples/sec: 115.58\n",
            "2020-02-03 18:15:03,090 epoch 96 - iter 18/64 - loss 0.44318987 - samples/sec: 107.35\n",
            "2020-02-03 18:15:06,276 epoch 96 - iter 24/64 - loss 0.46750971 - samples/sec: 97.22\n",
            "2020-02-03 18:15:09,337 epoch 96 - iter 30/64 - loss 0.46265635 - samples/sec: 104.06\n",
            "2020-02-03 18:15:12,543 epoch 96 - iter 36/64 - loss 0.69128757 - samples/sec: 96.33\n",
            "2020-02-03 18:15:15,225 epoch 96 - iter 42/64 - loss 0.65844747 - samples/sec: 129.29\n",
            "2020-02-03 18:15:18,807 epoch 96 - iter 48/64 - loss 0.64252854 - samples/sec: 84.50\n",
            "2020-02-03 18:15:21,856 epoch 96 - iter 54/64 - loss 0.62000140 - samples/sec: 94.42\n",
            "2020-02-03 18:15:24,779 epoch 96 - iter 60/64 - loss 0.60084063 - samples/sec: 112.77\n",
            "2020-02-03 18:15:26,832 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:15:26,837 EPOCH 96 done: loss 0.6034 - lr 0.0002\n",
            "2020-02-03 18:15:26,842 BAD EPOCHS (no improvement): 2\n",
            "2020-02-03 18:15:26,848 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:15:28,815 epoch 97 - iter 6/64 - loss 0.48082505 - samples/sec: 97.84\n",
            "2020-02-03 18:15:31,967 epoch 97 - iter 12/64 - loss 1.14712720 - samples/sec: 98.42\n",
            "2020-02-03 18:15:34,818 epoch 97 - iter 18/64 - loss 0.93682172 - samples/sec: 109.72\n",
            "2020-02-03 18:15:37,572 epoch 97 - iter 24/64 - loss 0.82343446 - samples/sec: 123.47\n",
            "2020-02-03 18:15:40,885 epoch 97 - iter 30/64 - loss 0.74702176 - samples/sec: 93.79\n",
            "2020-02-03 18:15:43,829 epoch 97 - iter 36/64 - loss 0.70086109 - samples/sec: 110.73\n",
            "2020-02-03 18:15:47,290 epoch 97 - iter 42/64 - loss 0.65795965 - samples/sec: 92.73\n",
            "2020-02-03 18:15:50,183 epoch 97 - iter 48/64 - loss 0.64912851 - samples/sec: 113.57\n",
            "2020-02-03 18:15:53,070 epoch 97 - iter 54/64 - loss 0.62717097 - samples/sec: 107.63\n",
            "2020-02-03 18:15:56,065 epoch 97 - iter 60/64 - loss 0.60502505 - samples/sec: 106.92\n",
            "2020-02-03 18:15:58,362 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:15:58,366 EPOCH 97 done: loss 0.5985 - lr 0.0002\n",
            "2020-02-03 18:15:58,368 BAD EPOCHS (no improvement): 3\n",
            "2020-02-03 18:15:58,372 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:16:00,156 epoch 98 - iter 6/64 - loss 1.84181341 - samples/sec: 107.76\n",
            "2020-02-03 18:16:02,969 epoch 98 - iter 12/64 - loss 1.16500791 - samples/sec: 118.57\n",
            "2020-02-03 18:16:05,941 epoch 98 - iter 18/64 - loss 0.91487580 - samples/sec: 114.61\n",
            "2020-02-03 18:16:08,905 epoch 98 - iter 24/64 - loss 0.80479713 - samples/sec: 109.50\n",
            "2020-02-03 18:16:11,634 epoch 98 - iter 30/64 - loss 0.74842076 - samples/sec: 124.54\n",
            "2020-02-03 18:16:14,458 epoch 98 - iter 36/64 - loss 0.69234517 - samples/sec: 118.77\n",
            "2020-02-03 18:16:17,591 epoch 98 - iter 42/64 - loss 0.64885988 - samples/sec: 110.59\n",
            "2020-02-03 18:16:20,409 epoch 98 - iter 48/64 - loss 0.62750222 - samples/sec: 118.31\n",
            "2020-02-03 18:16:23,776 epoch 98 - iter 54/64 - loss 0.61839901 - samples/sec: 88.48\n",
            "2020-02-03 18:16:26,888 epoch 98 - iter 60/64 - loss 0.60737570 - samples/sec: 101.67\n",
            "2020-02-03 18:16:29,150 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:16:29,152 EPOCH 98 done: loss 0.5873 - lr 0.0002\n",
            "Epoch    88: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-02-03 18:16:29,155 BAD EPOCHS (no improvement): 4\n",
            "2020-02-03 18:16:29,161 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:16:29,165 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:16:29,167 learning rate too small - quitting training!\n",
            "2020-02-03 18:16:29,169 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-03 18:16:38,202 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-03 18:16:38,227 Testing using best model ...\n",
            "2020-02-03 18:16:55,682 0.8108\t0.7351\t0.7711\n",
            "2020-02-03 18:16:55,756 \n",
            "MICRO_AVG: acc 0.6274 - f1-score 0.7711\n",
            "MACRO_AVG: acc 0.6461 - f1-score 0.7808249999999999\n",
            "LOC        tp: 270 - fp: 52 - fn: 56 - tn: 270 - precision: 0.8385 - recall: 0.8282 - accuracy: 0.7143 - f1-score: 0.8333\n",
            "MIS        tp: 463 - fp: 159 - fn: 259 - tn: 463 - precision: 0.7444 - recall: 0.6413 - accuracy: 0.5255 - f1-score: 0.6890\n",
            "ORG        tp: 71 - fp: 20 - fn: 31 - tn: 71 - precision: 0.7802 - recall: 0.6961 - accuracy: 0.5820 - f1-score: 0.7358\n",
            "PER        tp: 353 - fp: 39 - fn: 71 - tn: 353 - precision: 0.9005 - recall: 0.8325 - accuracy: 0.7624 - f1-score: 0.8652\n",
            "2020-02-03 18:16:55,763 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [],\n",
              " 'dev_score_history': [],\n",
              " 'test_score': 0.7711,\n",
              " 'train_loss_history': [3.172825579531491,\n",
              "  2.8620729129761457,\n",
              "  2.818813595920801,\n",
              "  2.682724203914404,\n",
              "  2.6685585360974073,\n",
              "  2.473819114267826,\n",
              "  2.3081628242507577,\n",
              "  2.2218076083809137,\n",
              "  2.275531893596053,\n",
              "  2.028705706819892,\n",
              "  2.1643992317840457,\n",
              "  1.9209355618804693,\n",
              "  1.9390278719365597,\n",
              "  1.7682693805545568,\n",
              "  1.7305616401135921,\n",
              "  1.6950347041711211,\n",
              "  1.6182723054662347,\n",
              "  1.6481357077136636,\n",
              "  1.4688514498993754,\n",
              "  1.5491945748217404,\n",
              "  1.4592222971841693,\n",
              "  1.3856595065444708,\n",
              "  1.3779776208102703,\n",
              "  1.4254532614722848,\n",
              "  1.3874140912666917,\n",
              "  1.2932561771012843,\n",
              "  1.3340622717514634,\n",
              "  1.2529320986941457,\n",
              "  1.146693326998502,\n",
              "  1.2542378515936434,\n",
              "  1.1162492097355425,\n",
              "  1.002207463607192,\n",
              "  1.0813086568377912,\n",
              "  1.1486307717859745,\n",
              "  1.1181872319430113,\n",
              "  1.1388018010184169,\n",
              "  1.0236797551624477,\n",
              "  1.0332019729539752,\n",
              "  0.7871479587629437,\n",
              "  0.9167856257408857,\n",
              "  0.9108262681402266,\n",
              "  0.8464953559450805,\n",
              "  0.7848318433389068,\n",
              "  0.7886000024154782,\n",
              "  0.6513560793828219,\n",
              "  0.7967441380023956,\n",
              "  0.8496753238141537,\n",
              "  0.8946136524900794,\n",
              "  0.6976594482548535,\n",
              "  0.7860433193854988,\n",
              "  0.59636095399037,\n",
              "  0.720979378093034,\n",
              "  0.6452647619880736,\n",
              "  0.6358302901498973,\n",
              "  0.653258791193366,\n",
              "  0.6075803674757481,\n",
              "  0.7993538174778223,\n",
              "  0.7240689545869827,\n",
              "  0.6393191255629063,\n",
              "  0.589743644464761,\n",
              "  0.5278932540677488,\n",
              "  0.5362317715771496,\n",
              "  0.6182612800039351,\n",
              "  0.5925276335328817,\n",
              "  0.49003995303064585,\n",
              "  0.65562649583444,\n",
              "  0.613297977251932,\n",
              "  0.5980502092279494,\n",
              "  0.5741077866405249,\n",
              "  0.5786433834582567,\n",
              "  0.6939429622143507,\n",
              "  0.521733928937465,\n",
              "  0.5638868636451662,\n",
              "  0.5055455919355154,\n",
              "  0.4912890396080911,\n",
              "  0.600852114148438,\n",
              "  0.613557246979326,\n",
              "  0.5114003913477063,\n",
              "  0.5285157947801054,\n",
              "  0.5579518033191562,\n",
              "  0.5449880142696202,\n",
              "  0.6806030408479273,\n",
              "  0.5501534887589514,\n",
              "  0.590517935808748,\n",
              "  0.6534302626969293,\n",
              "  0.5595830078236759,\n",
              "  0.6033695684745908,\n",
              "  0.5985454777255654,\n",
              "  0.5873082997277379]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aozUj1PR1Mwc",
        "outputId": "5eeb2691-a4d2-45df-e16f-b23d818f541f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "\n",
        "from flair.models import SequenceTagger\n",
        "model = SequenceTagger.load('/content/gdrive/My Drive/resources/taggers/example-ner/final-model.pt')\n",
        "from flair.data import Sentence\n",
        "# create example sentence\n",
        "sentence = Sentence('إياد ومريم إبنه عمران يلعبون فى الحديقة') \n",
        "\n",
        "# predict tags and print\n",
        "model.predict(sentence)\n",
        "#model.evaluate()\n",
        "print(sentence.to_tagged_string('ner'))\n",
        "\n",
        "for token in sentence:\n",
        "    tag = token.get_tag('ner')\n",
        "    print(f'\"{token}\" is tagged as \"{tag.value}\" with confidence score \"{tag.score}\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-12 16:51:58,022 loading file /content/gdrive/My Drive/resources/taggers/example-ner/final-model.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-55321fa873a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# predict tags and print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#model.evaluate()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tagged_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentences, mini_batch_size, embedding_storage_mode, all_tag_prob, verbose, use_tokenizer)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0mfeature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 tags, all_tags = self._obtain_labels(\n\u001b[1;32m    360\u001b[0m                     \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mlengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   2155\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m                             aggregated_embedding = self.aggregate_op(\n\u001b[0;32m-> 2157\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m                             )\n\u001b[1;32m   2159\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fade\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #2 'other' in call to _th_max"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsVrwriyT77l"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlkQKL2lAv-D"
      },
      "source": [
        "%config IPCompleter.greedy=True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EU3QrTLOgEH",
        "outputId": "bb09094d-8431-49fa-9d1b-0f4e4c553280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-10 17:53:12,274 loading file /content/gdrive/My Drive/resources/taggers/example-ner/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bngabPKOOpSN",
        "outputId": "6cdf3bb7-4331-4a81-af65-d933d375fa0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.models import SequenceTagger\n",
        "from flair.datasets import DataLoader, CONLL_03\n",
        "\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "data_folder = '/content/gdrive/My Drive/resources/tasks/conll_03'\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns, train_file=None,dev_file=None, \n",
        "                               test_file='ANERCorp1.txt', document_separator_token='.')\n",
        "\n",
        "model = SequenceTagger.load('/content/gdrive/My Drive/resources/taggers/example-ner/final-model.pt')    \n",
        "result, score =model.evaluate(DataLoader(corpus.test,batch_size=1),   '/content/gdrive/My Drive/resources/taggers/example-ner/pred.txt', embedding_storage_mode='cpu')\n",
        "\n",
        "print(result.log_line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-13 10:55:38,289 Reading data from /content/gdrive/My Drive/resources/tasks/conll_03\n",
            "2020-02-13 10:55:38,291 Train: /content/gdrive/My Drive/resources/tasks/conll_03/train.txt\n",
            "2020-02-13 10:55:38,292 Dev: /content/gdrive/My Drive/resources/tasks/conll_03/dev.txt\n",
            "2020-02-13 10:55:38,298 Test: /content/gdrive/My Drive/resources/tasks/conll_03/ANERCorp1.txt\n",
            "2020-02-13 10:55:41,037 loading file /content/gdrive/My Drive/resources/taggers/example-ner/final-model.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8518fc72cff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/resources/taggers/example-ner/final-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m'/content/gdrive/My Drive/resources/taggers/example-ner/pred.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_storage_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data_loader, out_path, embedding_storage_mode)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                     tags, _ = self._obtain_labels(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mlengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   2155\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m                             aggregated_embedding = self.aggregate_op(\n\u001b[0;32m-> 2157\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m                             )\n\u001b[1;32m   2159\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fade\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #2 'other' in call to _th_max"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jsC2tI5XKn5",
        "outputId": "3fa9ee61-64b4-4264-c8bf-ed44432c73dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(40.1316)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ScRhfVejxDr",
        "outputId": "60bb90ce-8c19-4fdd-ea95-85999749cdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.models import SequenceTagger\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "data_folder = '/content/gdrive/My Drive/resources/tasks/conll_03'\n",
        "cc: Corpus = ColumnCorpus    (data_folder, columns, train_file=None,dev_file=None, \n",
        "                               test_file='ANERCorp1.txt',document_separator_token='.')\n",
        "print(\"--- 1 Original ---\")\n",
        "print(cc)\n",
        "\n",
        "print(\"--- 2 Downsampled ---\")\n",
        "print(cc.test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-13 10:49:27,196 Reading data from /content/gdrive/My Drive/resources/tasks/conll_03\n",
            "2020-02-13 10:49:27,197 Train: /content/gdrive/My Drive/resources/tasks/conll_03/train.txt\n",
            "2020-02-13 10:49:27,198 Dev: /content/gdrive/My Drive/resources/tasks/conll_03/dev.txt\n",
            "2020-02-13 10:49:27,200 Test: /content/gdrive/My Drive/resources/tasks/conll_03/ANERCorp1.txt\n",
            "--- 1 Original ---\n",
            "Corpus: 1148 train + 613 dev + 4686 test sentences\n",
            "--- 2 Downsampled ---\n",
            "Sentence: \"فرانكفورت أعلن اتحاد صناعة السيارات في ألمانيا امس الاول أن شركات صناعة السيارات في ألمانيا تواجه عاما صعبا في ظل ركود السوق الداخلية والصادرات وهي تسعي لان يبلغ الانتاج حوالي خمسة ملايين سيارة في عام 2002\" - 36 Tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkxKWo9Exjpg",
        "outputId": "21d78a9a-03fa-4568-bbc0-88c8c874a1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"--- 2 Downsampled ---\")\n",
        "print(cc.train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 2 Downsampled ---\n",
            "Sentence: \"وعددها 18 مجموعة .\" - 4 Tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEzwRMOMtbSs"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_gLdKEaSRdk",
        "outputId": "0bcf3f26-e03a-4a0b-dedd-2428f1ca61ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "print(torch.version.cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCBCw1el9d3w",
        "outputId": "3ce53cf2-7662-416d-8799-85f299b19603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2a3e234bd3fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tagged_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj2WdNmOorFK"
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('1')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}